<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>cdbcf1a4f5714aabb34d7b6165b7e0cd</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<section id="summary" class="cell markdown" data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<h1>SUMMARY</h1>
<p>Для задачи предсказания зароботной платы были проведены эксперименты со следующими моделями:</p>
<pre><code>1) SalaryPredictor - базовая модель со сверточными слоями, нормированием по слоям и эмбеддингами, инициализируемых случайно
2) SalaryPredictorBatchNorm - с нормированием по батчам
3) SalaryPredictorLayerNorm - с нормированием по слоям
4) SalaryPredictorParallelConv - параллельные сверточные слои
5) SalaryPredictorStackMoreLayers - с удвоенным количеством слоев
6) SalaryPredictorEarlyStopping - базовая модель с остановкой обучения после 5 эпохи
7) SalaryPredictorMaxPool - с пулингом максимального значения
8) SalaryPredictorAvgPool - с пулингом усредненного значения
9) SalaryPredictorPretrainedEmbeddings - с предобученными эмбеддингами *glove-wiki-gigaword-50*
10) SalaryPredictorPretrainedEmbeddingsTrainedWeights - с предобученными эмбеддингами и их дообучением
11) SalaryPredictorLSTM - со слоями LSTM вместо сверточных для текстовых признаков
12) SalaryPredictorBidirectionalLSTM - с двунаправленными LSTM
13) SalaryPredictorRandomForest - с ансамблем деревьев решений в качестве последнего слоя для SalaryPredictorLayerNorm
14) SalaryPredictorSoftmaxPooling - с пулингом значений после функции Softmax
15) SalaryPredictorAttentivePooling - с пулингом значений после функции Attention</code></pre>
<p><strong><em><a href="https://tensorboard.dev/experiment/sOyIrKlBRTGmYkrSvh9p4g/#scalars">Графики функции потерь и метрик MSE и MAE</a></em></strong></p>
<p>Лучшее качество показала модель со сверточными слоями, механизмом внимания и эмбеддингами, инициализируемых случайно (<strong><em>SalaryPredictorAttentivePooling</em></strong>) - MSE <strong>0.024</strong>. Некоторые другие модели показали качество немногим хуже, но все еще очень хорошее MSE 0.027:</p>
<ul>
<li>с нормированием SalaryPredictorBatchNorm и SalaryPredictorLayerNorm</li>
<li>с предобученными эмбеддингами и их дообучением (<em>SalaryPredictorPretrainedEmbeddingsTrainedWeights</em>)</li>
<li>сеть с двунаправленными реккурентными слоями для обработки текстовых признаков (<em>SalaryPredictorBidirectionalLSTM</em>)</li>
</ul>
<p>Все модели имели поведение на обучении похожее между собой (см. графики), кроме:</p>
<ul>
<li>базовой модели <em>SalaryPredictor</em>, которая имеет более долгую и плавную сходимость</li>
<li>модели с большим количеством слоев <em>SalaryPredictorStackMoreLayers</em>, которая дольше сходилась из-за большого количества параметров</li>
<li>модели с параллельными свертками <em>SalaryPredictorParallelConv</em> - также из-за большего числа параметров и возросшей сложности</li>
<li>и ансамбля из деревьев решений в качестве регрессионнного слоя <em>SalaryPredictorRandomForest</em> и признаков из обученной сети, которые сошлись моментально</li>
</ul>
<p>Для обучения базовой модели необходимо <strong>5</strong> эпох (см. <em>SalaryPredictorEarlyStopping</em>)</p>
</section>
<section id="large-scale-text-analysis-with-deep-learning-3-points" class="cell markdown">
<h1>Large scale text analysis with deep learning (3 points)</h1>
<p>Today we're gonna apply the newly learned tools for the task of predicting job salary.</p>
<p><img src="https://storage.googleapis.com/kaggle-competitions/kaggle/3342/media/salary%20prediction%20engine%20v2.png" width=400px></p>
<p><em>Special thanks to <a href="https://github.com/Omrigan/">Oleg Vasilev</a> for the core assignment idea.</em></p>
</section>
<div class="cell code" id="YWS0E8OHZe8s" data-pycharm="{&quot;is_executing&quot;:true}">
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> kaggle</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span></code></pre></div>
</div>
<section id="about-the-challenge" class="cell markdown" id="JbjrfFspZe8s">
<h3>About the challenge</h3>
<p>For starters, let's download and unpack the data from [here].</p>
<p>You can also get it from <a href="https://yadi.sk/d/vVEOWPFY3NruT7">yadisk url</a> the competition <a href="https://www.kaggle.com/c/job-salary-prediction/data">page</a> (pick <code>Train_rev1.*</code>).</p>
</section>
<div class="cell code" data-pycharm="{&quot;is_executing&quot;:true,&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>kaggle.api.authenticate()</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>kaggle.api.competition_download_files(<span class="st">&#39;job-salary-prediction&#39;</span>, path<span class="op">=</span><span class="st">&#39;.&#39;</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> zipfile.ZipFile(<span class="st">&#39;job-salary-prediction.zip&#39;</span>, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> zip_ref:</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    zip_ref.extractall(<span class="st">&#39;job-salary-prediction&#39;</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> zipfile.ZipFile(<span class="st">&#39;job-salary-prediction/Train_rev1.zip&#39;</span>, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> zip_ref:</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    zip_ref.extractall(<span class="st">&#39;job-salary-prediction/Train_rev1&#39;</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> zipfile.ZipFile(<span class="st">&#39;job-salary-prediction/Test_rev1.zip&#39;</span>, <span class="st">&#39;r&#39;</span>) <span class="im">as</span> zip_ref:</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    zip_ref.extractall(<span class="st">&#39;job-salary-prediction/Test_rev1&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="2" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:15652,&quot;timestamp&quot;:1624451929807}" id="qsBw4DmiZe8t" data-outputId="e441fd46-3f1e-4833-e88e-b8df2e4f068d">
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> pd.read_csv(<span class="st">&quot;job-salary-prediction/Train_rev1/Train_rev1.csv&quot;</span>, index_col<span class="op">=</span><span class="va">None</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>data.shape</span></code></pre></div>
<div class="output execute_result" data-execution_count="2">
<pre><code>(244768, 12)</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="3" data-colab="{&quot;height&quot;:495,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:8,&quot;timestamp&quot;:1624451929807}" id="NaYFLUUsZe8u" data-outputId="8915d572-44b1-41d7-c658-fae0fc270530">
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>data.head()</span></code></pre></div>
<div class="output execute_result" data-execution_count="3">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>Title</th>
      <th>FullDescription</th>
      <th>LocationRaw</th>
      <th>LocationNormalized</th>
      <th>ContractType</th>
      <th>ContractTime</th>
      <th>Company</th>
      <th>Category</th>
      <th>SalaryRaw</th>
      <th>SalaryNormalized</th>
      <th>SourceName</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>12612628</td>
      <td>Engineering Systems Analyst</td>
      <td>Engineering Systems Analyst Dorking Surrey Sal...</td>
      <td>Dorking, Surrey, Surrey</td>
      <td>Dorking</td>
      <td>NaN</td>
      <td>permanent</td>
      <td>Gregory Martin International</td>
      <td>Engineering Jobs</td>
      <td>20000 - 30000/annum 20-30K</td>
      <td>25000</td>
      <td>cv-library.co.uk</td>
    </tr>
    <tr>
      <th>1</th>
      <td>12612830</td>
      <td>Stress Engineer Glasgow</td>
      <td>Stress Engineer Glasgow Salary **** to **** We...</td>
      <td>Glasgow, Scotland, Scotland</td>
      <td>Glasgow</td>
      <td>NaN</td>
      <td>permanent</td>
      <td>Gregory Martin International</td>
      <td>Engineering Jobs</td>
      <td>25000 - 35000/annum 25-35K</td>
      <td>30000</td>
      <td>cv-library.co.uk</td>
    </tr>
    <tr>
      <th>2</th>
      <td>12612844</td>
      <td>Modelling and simulation analyst</td>
      <td>Mathematical Modeller / Simulation Analyst / O...</td>
      <td>Hampshire, South East, South East</td>
      <td>Hampshire</td>
      <td>NaN</td>
      <td>permanent</td>
      <td>Gregory Martin International</td>
      <td>Engineering Jobs</td>
      <td>20000 - 40000/annum 20-40K</td>
      <td>30000</td>
      <td>cv-library.co.uk</td>
    </tr>
    <tr>
      <th>3</th>
      <td>12613049</td>
      <td>Engineering Systems Analyst / Mathematical Mod...</td>
      <td>Engineering Systems Analyst / Mathematical Mod...</td>
      <td>Surrey, South East, South East</td>
      <td>Surrey</td>
      <td>NaN</td>
      <td>permanent</td>
      <td>Gregory Martin International</td>
      <td>Engineering Jobs</td>
      <td>25000 - 30000/annum 25K-30K negotiable</td>
      <td>27500</td>
      <td>cv-library.co.uk</td>
    </tr>
    <tr>
      <th>4</th>
      <td>12613647</td>
      <td>Pioneer, Miser Engineering Systems Analyst</td>
      <td>Pioneer, Miser  Engineering Systems Analyst Do...</td>
      <td>Surrey, South East, South East</td>
      <td>Surrey</td>
      <td>NaN</td>
      <td>permanent</td>
      <td>Gregory Martin International</td>
      <td>Engineering Jobs</td>
      <td>20000 - 30000/annum 20-30K</td>
      <td>25000</td>
      <td>cv-library.co.uk</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<div class="cell markdown" id="GzN578PlZe8v">
<p>One problem with salary prediction is that it's oddly distributed: there are many people who are paid standard salaries and a few that get tons o money. The distribution is fat-tailed on the right side, which is inconvenient for MSE minimization.</p>
<p>There are several techniques to combat this: using a different loss function, predicting log-target instead of raw target or even replacing targets with their percentiles among all salaries in the training set. We gonna use logarithm for now.</p>
<p><em>You can read more <a href="https://www.kaggle.com/c/job-salary-prediction#description">in the official description</a>.</em></p>
</div>
<div class="cell code" data-execution_count="4" data-colab="{&quot;height&quot;:265,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:541,&quot;timestamp&quot;:1624451930343}" id="7m4_nPD5Ze8v" data-outputId="500dc396-ee5e-4ca1-9ccd-ee92c7cb3ae6">
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&#39;Log1pSalary&#39;</span>] <span class="op">=</span> np.log1p(data[<span class="st">&#39;SalaryNormalized&#39;</span>]).astype(<span class="st">&#39;float32&#39;</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>[<span class="dv">8</span>, <span class="dv">4</span>])</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>plt.hist(data[<span class="st">&quot;SalaryNormalized&quot;</span>], bins<span class="op">=</span><span class="dv">20</span>)</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>plt.hist(data[<span class="st">&#39;Log1pSalary&#39;</span>], bins<span class="op">=</span><span class="dv">20</span>)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_6bd0596d4e724493aefa0c6f0b1bc5e8/2e5faa50729c85086a016fecac6d8c936f6a940e.png" /></p>
</div>
</div>
<div class="cell markdown" id="FQ4sxIXDZe8w">
<p>Our task is to predict one number, <strong>Log1pSalary</strong>.</p>
<p>To do so, our model can access a number of features:</p>
<ul>
<li>Free text: <strong><code>Title</code></strong> and <strong><code>FullDescription</code></strong></li>
<li>Categorical: <strong><code>Category</code></strong>, <strong><code>Company</code></strong>, <strong><code>LocationNormalized</code></strong>, <strong><code>ContractType</code></strong>, and <strong><code>ContractTime</code></strong>.</li>
</ul>
</div>
<div class="cell code" data-execution_count="5" data-colab="{&quot;height&quot;:348,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:17,&quot;timestamp&quot;:1624451930343}" id="6dYdc8PIZe8w" data-outputId="1660641f-adb1-4215-ba25-cc0c0b8c1023">
<div class="sourceCode" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>text_columns <span class="op">=</span> [<span class="st">&quot;Title&quot;</span>, <span class="st">&quot;FullDescription&quot;</span>]</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>categorical_columns <span class="op">=</span> [<span class="st">&quot;Category&quot;</span>, <span class="st">&quot;Company&quot;</span>, <span class="st">&quot;LocationNormalized&quot;</span>, <span class="st">&quot;ContractType&quot;</span>, <span class="st">&quot;ContractTime&quot;</span>]</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>TARGET_COLUMN <span class="op">=</span> <span class="st">&quot;Log1pSalary&quot;</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>data[categorical_columns] <span class="op">=</span> data[categorical_columns].fillna(<span class="st">&#39;NaN&#39;</span>) <span class="co"># cast missing values to string &quot;NaN&quot;</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>data[text_columns] <span class="op">=</span> data[text_columns].fillna(<span class="st">&#39;NaN&#39;</span>)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>data.sample(<span class="dv">3</span>)</span></code></pre></div>
<div class="output execute_result" data-execution_count="5">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Id</th>
      <th>Title</th>
      <th>FullDescription</th>
      <th>LocationRaw</th>
      <th>LocationNormalized</th>
      <th>ContractType</th>
      <th>ContractTime</th>
      <th>Company</th>
      <th>Category</th>
      <th>SalaryRaw</th>
      <th>SalaryNormalized</th>
      <th>SourceName</th>
      <th>Log1pSalary</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>24695</th>
      <td>67745996</td>
      <td>RMN's required  Maidstone</td>
      <td>We have RMN vacancies at Glenhurst Lodge, an i...</td>
      <td>Maidstone</td>
      <td>Maidstone</td>
      <td>full_time</td>
      <td>NaN</td>
      <td>Glen Care Group</td>
      <td>Healthcare &amp; Nursing Jobs</td>
      <td>21,259 - 26,657/Year</td>
      <td>23958</td>
      <td>staffnurse.com</td>
      <td>10.084100</td>
    </tr>
    <tr>
      <th>76525</th>
      <td>69007545</td>
      <td>Vocational Instructor of Electrical Engineering</td>
      <td>A Technical Training provider is looking for a...</td>
      <td>Middlesbrough, North Yorkshire</td>
      <td>Middlesbrough</td>
      <td>NaN</td>
      <td>permanent</td>
      <td>Alderwood Education</td>
      <td>Teaching Jobs</td>
      <td>26179/annum</td>
      <td>26179</td>
      <td>cv-library.co.uk</td>
      <td>10.172751</td>
    </tr>
    <tr>
      <th>30763</th>
      <td>68065790</td>
      <td>Motor Vehicle Technician  fully qualifed</td>
      <td>The market leading vehicle hire company by fle...</td>
      <td>Aberdeen Aberdeenshire Scotland</td>
      <td>Aberdeen</td>
      <td>NaN</td>
      <td>permanent</td>
      <td>Northgate</td>
      <td>Other/General Jobs</td>
      <td>From 23,290 to 23,290 per annum</td>
      <td>23290</td>
      <td>totaljobs.com</td>
      <td>10.055822</td>
    </tr>
  </tbody>
</table>
</div>
</div>
</div>
<section id="preprocessing-text-data" class="cell markdown" id="sJGyz6vgZe8w">
<h3>Preprocessing text data</h3>
<p>Just like last week, applying NLP to a problem begins from tokenization: splitting raw text into sequences of tokens (words, punctuation, etc).</p>
<p><strong>Your task</strong> is to lowercase and tokenize all texts under <code>Title</code> and <code>FullDescription</code> columns. Store the tokenized data as a <strong>space-separated</strong> string of tokens for performance reasons.</p>
<p>It's okay to use nltk tokenizers. Assertions were designed for WordPunctTokenizer, slight deviations are okay.</p>
</section>
<div class="cell code" data-execution_count="6" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:16,&quot;timestamp&quot;:1624451930344}" id="djOwAHFHZe8w" data-outputId="0fd7d361-66be-474e-9d4c-b6378937bc36" data-scrolled="true">
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Raw text:&quot;</span>)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data[<span class="st">&quot;FullDescription&quot;</span>][<span class="dv">2</span>::<span class="dv">100000</span>])</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Raw text:
2         Mathematical Modeller / Simulation Analyst / O...
100002    A successful and high achieving specialist sch...
200002    Web Designer  HTML, CSS, JavaScript, Photoshop...
Name: FullDescription, dtype: object
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="7" id="pNGh27ebZe8x">
<div class="sourceCode" id="cb11"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> re</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> tokenize(text):</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">&#39; &#39;</span>.join(re.findall(<span class="st">&#39;\w+&#39;</span>, text.lower()))</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>data[text_columns] <span class="op">=</span> data[text_columns].applymap(tokenize)</span></code></pre></div>
</div>
<div class="cell markdown" id="HSSSLCO1Ze8x">
<p>Now we can assume that our text is a space-separated list of tokens:</p>
</div>
<div class="cell code" data-execution_count="8" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:18,&quot;timestamp&quot;:1624451948453}" id="iWpQuVt7Ze8x" data-outputId="33d24fe4-abd1-46dc-ef33-b77dba376912">
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Tokenized:&quot;</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(data[<span class="st">&quot;FullDescription&quot;</span>][<span class="dv">2</span>::<span class="dv">100000</span>])</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> data[<span class="st">&quot;FullDescription&quot;</span>][<span class="dv">2</span>][:<span class="dv">50</span>] <span class="op">==</span> <span class="st">&#39;mathematical modeller simulation analyst operation&#39;</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> data[<span class="st">&quot;Title&quot;</span>][<span class="dv">54321</span>] <span class="op">==</span> <span class="st">&#39;international digital account manager german&#39;</span></span></code></pre></div>
<div class="output stream stdout">
<pre><code>Tokenized:
2         mathematical modeller simulation analyst opera...
100002    a successful and high achieving specialist sch...
200002    web designer html css javascript photoshop ill...
Name: FullDescription, dtype: object
</code></pre>
</div>
</div>
<div class="cell markdown">
<p>Not all words are equally useful. Some of them are typos or rare words that are only present a few times.</p>
<p>Let's count how many times is each word present in the data so that we can build a "white list" of known words.</p>
</div>
<div class="cell code" data-execution_count="9" id="bVN-jztCZe8x">
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> collections <span class="im">import</span> Counter</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>token_counts <span class="op">=</span> Counter()</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Count how many times does each token occur in both &quot;Title&quot; and &quot;FullDescription&quot; in total</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col <span class="kw">in</span> text_columns:</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> line <span class="kw">in</span> data[col].values:</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        token_counts.update(line.split(<span class="st">&quot; &quot;</span>))</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="10" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:314,&quot;timestamp&quot;:1624451959707}" id="b-40HetcZe8y" data-outputId="2247cf66-4dba-4344-943b-bc87482043b7">
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Total unique tokens :&quot;</span>, <span class="bu">len</span>(token_counts))</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>.join(<span class="bu">map</span>(<span class="bu">str</span>, token_counts.most_common(n<span class="op">=</span><span class="dv">5</span>))))</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;...&#39;</span>)</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>.join(<span class="bu">map</span>(<span class="bu">str</span>, token_counts.most_common()[<span class="op">-</span><span class="dv">3</span>:])))</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> token_counts.most_common(<span class="dv">1</span>)[<span class="dv">0</span>][<span class="dv">1</span>] <span class="kw">in</span>  <span class="bu">range</span>(<span class="dv">2600000</span>, <span class="dv">2700000</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">len</span>(token_counts) <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">200000</span>, <span class="dv">210000</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;Correct!&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Total unique tokens : 201698
(&#39;and&#39;, 2657388)
(&#39;the&#39;, 2080994)
(&#39;to&#39;, 2019884)
(&#39;a&#39;, 1521925)
(&#39;of&#39;, 1426213)
...
(&#39;stephanietraveltraderecruitmnt&#39;, 1)
(&#39;ruabon&#39;, 1)
(&#39;lowehays&#39;, 1)
Correct!
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="11" data-colab="{&quot;height&quot;:279,&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:611,&quot;timestamp&quot;:1624451960316}" id="GNCP31cKZe8y" data-outputId="47ec110e-6336-4510-8076-4b96853d89a9">
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let&#39;s see how many words are there for each count</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>plt.hist(<span class="bu">list</span>(token_counts.values()), <span class="bu">range</span><span class="op">=</span>[<span class="dv">0</span>, <span class="dv">10</span><span class="op">**</span><span class="dv">4</span>], bins<span class="op">=</span><span class="dv">50</span>, log<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&quot;Word counts&quot;</span>)<span class="op">;</span></span></code></pre></div>
<div class="output display_data">
<p><img src="vertopal_6bd0596d4e724493aefa0c6f0b1bc5e8/598eca4580af8d7b4d8ffad417a9d69b777bd55d.png" /></p>
</div>
</div>
<div class="cell markdown" id="cIWo0dm5Ze8y">
<p><strong>Task 1.1</strong> Get a list of all tokens that occur at least 10 times.</p>
</div>
<div class="cell code" data-execution_count="12" id="iUB3KExsZe8y">
<div class="sourceCode" id="cb18"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>min_count <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co"># tokens from token_counts keys that had at least min_count occurrences throughout the dataset</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> <span class="bu">sorted</span>(t <span class="cf">for</span> t, c <span class="kw">in</span> token_counts.items() <span class="cf">if</span> c <span class="op">&gt;=</span> min_count)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Add a special tokens for unknown and empty words</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>UNK, PAD <span class="op">=</span> <span class="st">&quot;UNK&quot;</span>, <span class="st">&quot;PAD&quot;</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> [UNK, PAD] <span class="op">+</span> tokens</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="13" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:15,&quot;timestamp&quot;:1624451960317}" id="kqDMQVGyZe8y" data-outputId="0b24fbe4-afb8-4b82-af42-48bbd2775f9a">
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Vocabulary size:&quot;</span>, <span class="bu">len</span>(tokens))</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">type</span>(tokens) <span class="op">==</span> <span class="bu">list</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">len</span>(tokens) <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">32000</span>, <span class="dv">35000</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="st">&#39;me&#39;</span> <span class="kw">in</span> tokens</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> UNK <span class="kw">in</span> tokens</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Correct!&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Vocabulary size: 33816
Correct!
</code></pre>
</div>
</div>
<div class="cell markdown" id="Z8JGwF9VZe8z">
<p><strong>Task 1.2</strong> Build an inverse token index: a dictionary from token(string) to it's index in <code>tokens</code> (int)</p>
</div>
<div class="cell code" data-execution_count="14" id="XcrdkC_RZe8z">
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>token_to_id <span class="op">=</span> {t: i <span class="cf">for</span> i, t <span class="kw">in</span> <span class="bu">enumerate</span>(tokens)}</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="15" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:13,&quot;timestamp&quot;:1624451960318}" id="MrfWfH7MZe8z" data-outputId="1e0f9607-694e-400b-91a0-eaf671dbd912">
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">isinstance</span>(token_to_id, <span class="bu">dict</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">len</span>(token_to_id) <span class="op">==</span> <span class="bu">len</span>(tokens)</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> tok <span class="kw">in</span> tokens:</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> tokens[token_to_id[tok]] <span class="op">==</span> tok</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Correct!&quot;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Correct!
</code></pre>
</div>
</div>
<div class="cell markdown" id="wYj9cyTXZe8z">
<p>And finally, let's use the vocabulary you've built to map text lines into neural network-digestible matrices.</p>
</div>
<div class="cell code" data-execution_count="16" id="ExQNSGMrZe8z">
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>UNK_IX, PAD_IX <span class="op">=</span> <span class="bu">map</span>(token_to_id.get, [UNK, PAD])</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> as_matrix(sequences, max_len<span class="op">=</span><span class="dv">8</span>):</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot; Convert a list of tokens into a matrix with padding &quot;&quot;&quot;</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(sequences[<span class="dv">0</span>], <span class="bu">str</span>):</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>        sequences <span class="op">=</span> <span class="bu">list</span>(<span class="bu">map</span>(<span class="bu">str</span>.split, sequences))</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    matrix <span class="op">=</span> np.full((<span class="bu">len</span>(sequences), max_len), np.int32(PAD_IX))</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i,seq <span class="kw">in</span> <span class="bu">enumerate</span>(sequences):</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>        row_ix <span class="op">=</span> [token_to_id.get(word, UNK_IX) <span class="cf">for</span> word <span class="kw">in</span> seq[:max_len]]</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>        matrix[i, :<span class="bu">len</span>(row_ix)] <span class="op">=</span> row_ix</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> matrix</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="17" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:10,&quot;timestamp&quot;:1624451960319}" id="5bd1OxoyZe80" data-outputId="725f51df-76bd-4758-f176-6da347d8d021">
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Lines:&quot;</span>)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">&#39;</span>.join(data[<span class="st">&quot;Title&quot;</span>][::<span class="dv">100000</span>].values), end<span class="op">=</span><span class="st">&#39;</span><span class="ch">\n\n</span><span class="st">&#39;</span>)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Matrix:&quot;</span>)</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(as_matrix(data[<span class="st">&quot;Title&quot;</span>][::<span class="dv">100000</span>]))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Lines:
engineering systems analyst
hr assistant
senior ec i engineer

Matrix:
[[10527 29881  1886     1     1     1     1     1]
 [14740  2564     1     1     1     1     1     1]
 [27365  9921 14935 10524     1     1     1     1]]
</code></pre>
</div>
</div>
<div class="cell markdown" id="DsXCKzrUZe80">
<p>Now let's encode the categirical data we have.</p>
<p>As usual, we shall use one-hot encoding for simplicity. Kudos if you implement more advanced encodings: tf-idf, pseudo-time-series, etc.</p>
</div>
<div class="cell code" data-execution_count="18" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:6266,&quot;timestamp&quot;:1624451966578}" id="cr-qdrh3Ze81" data-outputId="4d64bcee-2d36-4b76-c317-d44759dce874">
<div class="sourceCode" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.feature_extraction <span class="im">import</span> DictVectorizer</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a><span class="co"># we only consider top-1k most frequent companies to minimize memory usage</span></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>top_companies, top_counts <span class="op">=</span> <span class="bu">zip</span>(<span class="op">*</span>Counter(data[<span class="st">&#39;Company&#39;</span>]).most_common(<span class="dv">1000</span>))</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>recognized_companies <span class="op">=</span> <span class="bu">set</span>(top_companies)</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>data[<span class="st">&quot;Company&quot;</span>] <span class="op">=</span> data[<span class="st">&quot;Company&quot;</span>].<span class="bu">apply</span>(<span class="kw">lambda</span> comp: comp <span class="cf">if</span> comp <span class="kw">in</span> recognized_companies <span class="cf">else</span> <span class="st">&quot;Other&quot;</span>)</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>categorical_vectorizer <span class="op">=</span> DictVectorizer(dtype<span class="op">=</span>np.float32, sparse<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>categorical_vectorizer.fit(data[categorical_columns].<span class="bu">apply</span>(<span class="bu">dict</span>, axis<span class="op">=</span><span class="dv">1</span>))</span></code></pre></div>
<div class="output execute_result" data-execution_count="18">
<pre><code>DictVectorizer(dtype=&lt;class &#39;numpy.float32&#39;&gt;, sparse=False)</code></pre>
</div>
</div>
<section id="the-deep-learning-part" class="cell markdown" id="mJDgbkHZZe81">
<h3>The deep learning part</h3>
<p>Once we've learned to tokenize the data, let's design a machine learning experiment.</p>
<p>As before, we won't focus too much on validation, opting for a simple train-test split.</p>
<p><strong>To be completely rigorous,</strong> we've comitted a small crime here: we used the whole data for tokenization and vocabulary building. A more strict way would be to do that part on training set only. You may want to do that and measure the magnitude of changes.</p>
</section>
<div class="cell code" data-execution_count="19" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:18,&quot;timestamp&quot;:1624451966578}" id="3sURw9HXZe81" data-outputId="39c9d1dc-07f4-4ab3-d5a8-2663b7e0ff6f">
<div class="sourceCode" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>data_train, data_val <span class="op">=</span> train_test_split(data, test_size<span class="op">=</span><span class="fl">0.1</span>, random_state<span class="op">=</span><span class="dv">77</span>)</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>data_train.index <span class="op">=</span> <span class="bu">range</span>(<span class="bu">len</span>(data_train))</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>data_val.index <span class="op">=</span> <span class="bu">range</span>(<span class="bu">len</span>(data_val))</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Train size =&quot;</span>, <span class="bu">len</span>(data_train))</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Validation size =&quot;</span>, <span class="bu">len</span>(data_val))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Train size = 220291
Validation size = 24477
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="20" id="Il8wpyN1Ze81">
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> to_tensors(batch, device):</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    batch_tensors <span class="op">=</span> <span class="bu">dict</span>()</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> key, arr <span class="kw">in</span> batch.items():</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> key <span class="kw">in</span> [<span class="st">&quot;FullDescription&quot;</span>, <span class="st">&quot;Title&quot;</span>]:</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>            batch_tensors[key] <span class="op">=</span> torch.tensor(arr, device<span class="op">=</span>device, dtype<span class="op">=</span>torch.int64)</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>            batch_tensors[key] <span class="op">=</span> torch.tensor(arr, device<span class="op">=</span>device)</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> batch_tensors</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_batch(data, max_lens<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">64</span>), word_dropout<span class="op">=</span><span class="dv">0</span>, device<span class="op">=</span>torch.device(<span class="st">&#39;cpu&#39;</span>)):</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;</span></span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a><span class="co">    Creates a keras-friendly dict from the batch data.</span></span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a><span class="co">    :param word_dropout: replaces token index with UNK_IX with this probability</span></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a><span class="co">    :returns: a dict with {&#39;title&#39; : int64[batch, title_max_len]</span></span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>    batch <span class="op">=</span> {<span class="st">&quot;Title&quot;</span>: as_matrix(data[<span class="st">&quot;Title&quot;</span>].values, max_lens[<span class="dv">0</span>]),</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>             <span class="st">&quot;FullDescription&quot;</span>: as_matrix(data[<span class="st">&quot;FullDescription&quot;</span>].values, max_lens[<span class="dv">1</span>]),</span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>             <span class="st">&#39;Categorical&#39;</span>: categorical_vectorizer.transform(data[categorical_columns].<span class="bu">apply</span>(<span class="bu">dict</span>, axis<span class="op">=</span><span class="dv">1</span>))}</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> word_dropout <span class="op">!=</span> <span class="dv">0</span>:</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>        batch[<span class="st">&quot;FullDescription&quot;</span>] <span class="op">=</span> apply_word_dropout(batch[<span class="st">&quot;FullDescription&quot;</span>], <span class="fl">1.</span> <span class="op">-</span> word_dropout)</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> TARGET_COLUMN <span class="kw">in</span> data.columns:</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>        batch[TARGET_COLUMN] <span class="op">=</span> data[TARGET_COLUMN].values</span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> to_tensors(batch, device)</span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> apply_word_dropout(matrix, keep_prop, replace_with<span class="op">=</span>UNK_IX, pad_ix<span class="op">=</span>PAD_IX,):</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>    dropout_mask <span class="op">=</span> np.random.choice(<span class="dv">2</span>, np.shape(matrix), p<span class="op">=</span>[keep_prop, <span class="dv">1</span> <span class="op">-</span> keep_prop])</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>    dropout_mask <span class="op">&amp;=</span> matrix <span class="op">!=</span> pad_ix</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> np.choose(dropout_mask, [matrix, np.full_like(matrix, replace_with)])</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="21" data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:399,&quot;timestamp&quot;:1624451970485}" id="dRKoBF_gZe82" data-outputId="aadc0cf5-8e62-4008-a968-e7e0b26bb085" data-scrolled="true">
<div class="sourceCode" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>make_batch(data_train[:<span class="dv">3</span>])</span></code></pre></div>
<div class="output execute_result" data-execution_count="21">
<pre><code>{&#39;Title&#39;: tensor([[27365, 26706,  1307, 10912,  1420,     1,     1,     1],
         [27000, 13370, 30129,  2564,     1,     1,     1,     1],
         [ 4706,  8803, 18584,     1,     1,     1,     1,     1]]),
 &#39;FullDescription&#39;: tensor([[32657, 30820, 33384, 12307,   702, 17473, 10912,  1413,  7830, 32980,
          13966,  1862, 11120, 21676, 12307,  1862, 10912,  1420, 30820, 16618,
            702,  9800, 29453,  1909, 13565, 10912,  1413, 15274, 21525, 21354,
          21929,  4745, 21382, 30466, 29453, 26706,  1307, 33155,  3362, 11283,
           1909, 31990, 30820,   981,  1909, 11110, 30026, 33286, 10912,  1413,
          11278,  2409,   702, 26706,  1307, 20543, 33483,  3362, 25729, 12307,
          30567, 26341, 26706, 20544],
         [ 2292, 33716,   702, 13370, 33274,   702,   223, 21741, 27000,  3267,
           8465,  9332, 33716, 13966,   702, 29272,   837, 25078,  2640, 12962,
           1909,  1594, 33483, 33716, 17797, 30820, 12806, 11278, 33409,  2409,
            702, 30129,  2564, 29892, 15274,  1862, 21993, 21410,   229, 27165,
          26995, 30820, 29613,  1909,  4062, 33723,  2132, 12307,   702, 22869,
          30567, 16171, 30466, 16546, 12307, 33716, 30129,  2564,   223, 21741,
            229,    51, 27000, 13370],
         [33716, 33155, 30043, 33274,  2722, 20613, 11032,  6871, 30820, 11013,
            795, 30466,  4706,  1909, 16302, 24170, 33716, 33155,  3362, 25729,
          30820,  4595, 29272, 25454, 33274, 23475,  6143, 18528, 30481,  2941,
          21354, 30466,  6620,  4230,  1909, 14715, 33716,  4967, 14178, 30477,
           4706, 33716, 33155,  3362, 27332, 30477,  7294, 24000,  1909, 27484,
          30820, 20638,  4717,  1909, 30491, 18503, 30466, 21542, 25451, 30820,
          10600, 12769, 26008, 29220]]),
 &#39;Categorical&#39;: tensor([[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]),
 &#39;Log1pSalary&#39;: tensor([10.5967,  9.5325, 10.4631])}</code></pre>
</div>
</div>
<section id="architecture" class="cell markdown" id="J8f9-Y01Ze82">
<h4>Architecture</h4>
<p>Our basic model consists of three branches:</p>
<ul>
<li>Title encoder</li>
<li>Description encoder</li>
<li>Categorical features encoder</li>
</ul>
<p>We will then feed all 3 branches into one common network that predicts salary.</p>
<p><img src="vertopal_6bd0596d4e724493aefa0c6f0b1bc5e8/ec1ea7dd535af19f2a0c560d07820d9f2767a29c.png" alt="scheme" /></p>
</section>
<div class="cell markdown" id="x-zT-Hu_Ze82">
<p>This clearly doesn't fit into keras' <strong>Sequential</strong> interface. To build such a network, one will have to use PyTorch.</p>
</div>
<div class="cell code" data-execution_count="22" id="obkMJ46pZe83">
<div class="sourceCode" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="23" id="F4LgLJtEZe83">
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SalaryPredictor(nn.Module):</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>,</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>                 n_tokens<span class="op">=</span><span class="bu">len</span>(tokens),</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>                 n_cat_features<span class="op">=</span><span class="bu">len</span>(categorical_vectorizer.vocabulary_),</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>                 hid_size<span class="op">=</span><span class="dv">8</span>):</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.hid_size <span class="op">=</span> hid_size</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_tokens <span class="op">=</span> n_tokens</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_cat_features <span class="op">=</span> n_cat_features</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedder <span class="op">=</span> nn.Embedding(<span class="va">self</span>.n_tokens, <span class="va">self</span>.hid_size)</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.title_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>            nn.Conv1d(<span class="va">self</span>.hid_size, <span class="va">self</span>.hid_size, kernel_size<span class="op">=</span>(<span class="dv">2</span>, )),</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveMaxPool1d(output_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.description_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>            nn.Conv1d(<span class="va">self</span>.hid_size, <span class="va">self</span>.hid_size, kernel_size<span class="op">=</span>(<span class="dv">2</span>, )),</span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveMaxPool1d(output_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.categorical_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.n_cat_features, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>            nn.ReLU()</span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.final_predictor <span class="op">=</span> nn.Sequential(</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>, <span class="va">self</span>.hid_size),</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size, <span class="dv">1</span>)</span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb35-35"><a href="#cb35-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-36"><a href="#cb35-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, batch):</span>
<span id="cb35-37"><a href="#cb35-37" aria-hidden="true" tabindex="-1"></a>        title_embeddings <span class="op">=</span> <span class="va">self</span>.embedder(batch[<span class="st">&#39;Title&#39;</span>]).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb35-38"><a href="#cb35-38" aria-hidden="true" tabindex="-1"></a>        title_features <span class="op">=</span> <span class="va">self</span>.title_encoder(title_embeddings).squeeze()</span>
<span id="cb35-39"><a href="#cb35-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-40"><a href="#cb35-40" aria-hidden="true" tabindex="-1"></a>        description_embeddings <span class="op">=</span> <span class="va">self</span>.embedder(batch[<span class="st">&#39;FullDescription&#39;</span>]).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb35-41"><a href="#cb35-41" aria-hidden="true" tabindex="-1"></a>        description_features <span class="op">=</span> <span class="va">self</span>.description_encoder(description_embeddings).squeeze()</span>
<span id="cb35-42"><a href="#cb35-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-43"><a href="#cb35-43" aria-hidden="true" tabindex="-1"></a>        categorical_features <span class="op">=</span> <span class="va">self</span>.categorical_encoder(batch[<span class="st">&#39;Categorical&#39;</span>])</span>
<span id="cb35-44"><a href="#cb35-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-45"><a href="#cb35-45" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> torch.cat(</span>
<span id="cb35-46"><a href="#cb35-46" aria-hidden="true" tabindex="-1"></a>            [title_features, description_features, categorical_features], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb35-47"><a href="#cb35-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-48"><a href="#cb35-48" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.final_predictor(features).squeeze()</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="25" id="JBS7PlCrZe83">
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SalaryPredictor()</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>batch <span class="op">=</span> make_batch(data_train[:<span class="dv">100</span>])</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>criterion <span class="op">=</span> nn.MSELoss()</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>dummy_pred <span class="op">=</span> model(batch)</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>dummy_loss <span class="op">=</span> criterion(dummy_pred, batch[TARGET_COLUMN])</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> dummy_pred.shape <span class="op">==</span> torch.Size([<span class="dv">100</span>])</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> <span class="bu">len</span>(np.unique(dummy_pred.detach().numpy())) <span class="op">&gt;</span> <span class="dv">20</span>, <span class="st">&quot;model returns suspiciously few unique outputs. Check your initialization&quot;</span></span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a><span class="cf">assert</span> dummy_loss.ndim <span class="op">==</span> <span class="dv">0</span> <span class="kw">and</span> <span class="fl">0.</span> <span class="op">&lt;=</span> dummy_loss <span class="op">&lt;=</span> <span class="fl">250.</span>, <span class="st">&quot;make sure you minimize MSE&quot;</span></span></code></pre></div>
</div>
<section id="training-and-evaluation" class="cell markdown" id="WmImJv70Ze83">
<h4>Training and evaluation</h4>
<p>As usual, we gonna feed our monster with random minibatches of data.</p>
<p>As we train, we want to monitor not only loss function, which is computed in log-space, but also the actual error measured in dollars.</p>
</section>
<div class="cell code" data-execution_count="24" id="lBwOV5duZe84">
<div class="sourceCode" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm.notebook <span class="im">import</span> trange</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> iterate_minibatches(data, batch_size<span class="op">=</span><span class="dv">256</span>, shuffle<span class="op">=</span><span class="va">True</span>, cycle<span class="op">=</span><span class="va">False</span>, tqdm<span class="op">=</span><span class="va">True</span>, <span class="op">**</span>kwargs):</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot; iterates minibatches of data in random order &quot;&quot;&quot;</span></span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span> <span class="va">True</span>:</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>        indices <span class="op">=</span> np.arange(<span class="bu">len</span>(data))</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> shuffle:</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>            indices <span class="op">=</span> np.random.permutation(indices)</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>        id_range <span class="op">=</span> trange(<span class="dv">0</span>, <span class="bu">len</span>(indices), batch_size) <span class="cf">if</span> tqdm <span class="cf">else</span> <span class="bu">range</span>(<span class="dv">0</span>, <span class="bu">len</span>(indices), batch_size)</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> start <span class="kw">in</span> id_range:</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>            batch <span class="op">=</span> make_batch(data.iloc[indices[start : start <span class="op">+</span> batch_size]], <span class="op">**</span>kwargs)</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> batch</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="kw">not</span> cycle:</span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span></code></pre></div>
</div>
<section id="model-training" class="cell markdown" id="H7ExfuFkZe84">
<h3>Model training</h3>
<p>We can now fit our model the usual minibatch way. The interesting part is that we train on an infinite stream of minibatches, produced by <code>iterate_minibatches</code> function.</p>
</section>
<div class="cell code" data-execution_count="25" id="qNW1PL0mZe84">
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">128</span></span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>VECTOR_SIZES <span class="op">=</span> (<span class="dv">8</span>, <span class="dv">64</span>)</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>EPOCHS <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>DEVICE <span class="op">=</span> torch.device(<span class="st">&#39;cpu&#39;</span>)</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="26" id="Bsu0gequZe84">
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metrics(model, data, batch_size<span class="op">=</span>BATCH_SIZE, <span class="op">**</span>kw):</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>    squared_error <span class="op">=</span> abs_error <span class="op">=</span> num_samples <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> iterate_minibatches(data, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">False</span>, tqdm<span class="op">=</span><span class="va">False</span>, <span class="op">**</span>kw):</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>            batch_pred <span class="op">=</span> model(batch)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>            squared_error <span class="op">+=</span> torch.mean(torch.square(batch_pred <span class="op">-</span> batch[TARGET_COLUMN]))</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>            abs_error <span class="op">+=</span> torch.mean(torch.<span class="bu">abs</span>(batch_pred <span class="op">-</span> batch[TARGET_COLUMN]))</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>            num_samples <span class="op">+=</span> <span class="bu">len</span>(batch)</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>    mse <span class="op">=</span> squared_error.detach().cpu().numpy() <span class="op">/</span> num_samples</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    mae <span class="op">=</span> abs_error.detach().cpu().numpy() <span class="op">/</span> num_samples</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mse, mae</span></code></pre></div>
</div>
<div class="cell code" data-execution_count="27" data-colab="{&quot;height&quot;:1000,&quot;referenced_widgets&quot;:[&quot;3a34a95aa682439fbce7c40ac232bfa3&quot;,&quot;30902776c0564143a69d7b6ebf0fe9b9&quot;,&quot;b5308c327f5c4395852638002e93312a&quot;,&quot;1c6445766414415e99ac32fb94686dca&quot;,&quot;7b79ef9602d041acada88a1e3e75fa7f&quot;,&quot;df3fe642b3184ce89286cd052f047cbd&quot;,&quot;d32c4d65bc164e30aca844c670363ae3&quot;,&quot;995b4b20bd094ab4b5a3d2027c45fdca&quot;,&quot;6505bbb46d7f4ffa9794fde8861cd8fb&quot;,&quot;03bbe0d4b0524a85be49a1b119aaa66a&quot;,&quot;0f5b3da7508f461595456f1316465dae&quot;,&quot;b6d38ddc1e4948c9b98a6d79c18cd5a5&quot;,&quot;b2b39e59a46a4338bc75afd376e69931&quot;,&quot;b680fa64dc604e6d94697242310428e9&quot;,&quot;4722c85bb02b4291a90e6402d86397fa&quot;,&quot;c34336639978471f8e0f6aa78e1955ff&quot;,&quot;a2b99faed0f54678811698f312ed80a4&quot;,&quot;df9c2a9f3fe04519853a361700e3c056&quot;,&quot;421c51a1bf9d4be4ad8c445ad5c6fce8&quot;,&quot;73e5ea94ed2c45f5b25d1281f66b59bf&quot;,&quot;cc9eef35c7da4872bac60bd46110fa04&quot;,&quot;98b0239d3c6c4c8ca82d0f7cb96734fe&quot;,&quot;2dae3fd3baad438aa9436206e741ac38&quot;,&quot;af9922f672f54841b5acb1379534d1e5&quot;],&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}" data-executionInfo="{&quot;status&quot;:&quot;ok&quot;,&quot;user&quot;:{&quot;photoUrl&quot;:&quot;&quot;,&quot;userId&quot;:&quot;06639583344500545085&quot;,&quot;displayName&quot;:&quot;Aleksey Shimko&quot;},&quot;user_tz&quot;:-180,&quot;elapsed&quot;:301404,&quot;timestamp&quot;:1624452272144}" id="guTdyDx1Ze84" data-outputId="e5686c5f-efba-4a6e-f161-4672ddaf92f8">
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.tensorboard <span class="im">import</span> SummaryWriter</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train(model, batch_size, epochs, device, vector_sizes, logdir<span class="op">=</span><span class="st">&#39;.&#39;</span>):</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>    writer <span class="op">=</span> SummaryWriter(log_dir<span class="op">=</span><span class="ss">f&#39;runs/</span><span class="sc">{</span>logdir<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> model.to(device)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.MSELoss(reduction<span class="op">=</span><span class="st">&#39;mean&#39;</span>)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">1e-3</span>)</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    one_epoch_n_iterates <span class="op">=</span> <span class="bu">len</span>(data_train) <span class="op">/</span> batch_size</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a>                iterate_minibatches(data_train, batch_size<span class="op">=</span>batch_size, device<span class="op">=</span>device, max_lens<span class="op">=</span>vector_sizes)):</span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>            model.train()</span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> model(batch)</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(pred, batch[TARGET_COLUMN])</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>            writer.add_scalar(<span class="ss">f&#39;train/loss&#39;</span>, loss.item(), i <span class="op">+</span> epoch <span class="op">*</span> one_epoch_n_iterates)</span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">99</span>:</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>                mse, mae <span class="op">=</span> metrics(model, data_val, batch_size<span class="op">=</span>batch_size, device<span class="op">=</span>device, max_lens<span class="op">=</span>vector_sizes)</span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a>                writer.add_scalar(<span class="ss">f&#39;val/Mean square error&#39;</span>, mse,</span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a>                                  i <span class="op">+</span> epoch <span class="op">*</span> one_epoch_n_iterates)</span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>                writer.add_scalar(<span class="ss">f&#39;val/Mean absolute error&#39;</span>, mae,</span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a>                                  i <span class="op">+</span> epoch <span class="op">*</span> one_epoch_n_iterates)</span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;Train Loss </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;Mean square error </span><span class="sc">{</span>mse<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;Mean absolute error </span><span class="sc">{</span>mae<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SalaryPredictor()</span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a>train(model, BATCH_SIZE, EPOCHS, DEVICE, VECTOR_SIZES, <span class="st">&#39;SalaryPredictor&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb42"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;cdaf6bdbb1734bc3aefcd8982a4da80a&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.2450
Mean square error 0.3443
Mean absolute error 0.2767
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb44"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;9f342752433743ddac31c2d714bcc978&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.1246
Mean square error 0.1699
Mean absolute error 0.1881
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb46"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5adf2a997b8b4c66b00743ffd49db2e1&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.2725
Mean square error 0.1086
Mean absolute error 0.1460
</code></pre>
</div>
</div>
<div class="cell markdown" data-pycharm="{&quot;is_executing&quot;:true,&quot;name&quot;:&quot;#%% md\n&quot;}">
<p><strong>Выводы:</strong> Salary Predictor - baseline (1 сверточный слой + dropout) для задачи, сходится достаточно хорошо и быстро при 8 нейронах в скрытых слоях, за 3 эпохи MSE падает до <strong>0.11</strong>. <a href="https://tensorboard.dev/experiment/sOyIrKlBRTGmYkrSvh9p4g/#scalars&amp;runSelectionState=eyJTYWxhcnlQcmVkaWN0b3IiOnRydWUsIlNhbGFyeVByZWRpY3RvckF0dGVudGl2ZVBvb2xpbmciOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JBdmdQb29sIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yQmF0Y2hOb3JtIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yQmlkaXJlY3Rpb25hbExTVE0iOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JFYXJseVN0b3BwaW5nIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yTFNUTSI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvckxheWVyTm9ybSI6ZmFsc2UsIlNhbGFyeVByZWRpY3Rvck1heFBvb2wiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JQYXJhbGxlbENvbnYiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JQcmV0cmFpbmVkRW1iZWRkaW5ncyI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvclByZXRyYWluZWRFbWJlZGRpbmdzVHJhaW5lZFdlaWdodHMiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JSYW5kb21Gb3Jlc3QiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JTb2Z0bWF4UG9vbGluZyI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvclN0YWNrTW9yZUxheWVycyI6ZmFsc2V9">Графики для Salary Predictor.</a></p>
</div>
<div class="cell markdown">
<p><strong>1. Развейте СNN архитектуру (2 балла)</strong></p>
<p>Добавьте в пайплайн</p>
<ul>
<li>Batch Norm (nn.BatchNorm), LayerNorm...</li>
<li>Параллельные сверточные слои. Идея в том, чтобы применить несколько nn.Conv1d к одному и тому же эмбеддингу и после этого сконкатенировать выходные каналы</li>
<li>Больше слоев...</li>
<li>Добавьте раннюю остановку</li>
</ul>
<p>На каких примерах модели ведут себя максимально различно/похоже? Предположите с чем это может быть связано.</p>
<p>Как модель ведет себя в зависимости от количества обучаемых параметров?</p>
<p><strong>Выводы и <a href="https://tensorboard.dev/experiment/sOyIrKlBRTGmYkrSvh9p4g/#scalars&amp;runSelectionState=eyJTYWxhcnlQcmVkaWN0b3IiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JBdHRlbnRpdmVQb29saW5nIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yQXZnUG9vbCI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvckJhdGNoTm9ybSI6dHJ1ZSwiU2FsYXJ5UHJlZGljdG9yQmlkaXJlY3Rpb25hbExTVE0iOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JFYXJseVN0b3BwaW5nIjp0cnVlLCJTYWxhcnlQcmVkaWN0b3JMU1RNIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yTGF5ZXJOb3JtIjp0cnVlLCJTYWxhcnlQcmVkaWN0b3JNYXhQb29sIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yUGFyYWxsZWxDb252Ijp0cnVlLCJTYWxhcnlQcmVkaWN0b3JQcmV0cmFpbmVkRW1iZWRkaW5ncyI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvclByZXRyYWluZWRFbWJlZGRpbmdzVHJhaW5lZFdlaWdodHMiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JSYW5kb21Gb3Jlc3QiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JTb2Z0bWF4UG9vbGluZyI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvclN0YWNrTW9yZUxheWVycyI6dHJ1ZX0%3D">Графики</a>:</strong></p>
<pre><code>1) Нормализация заметно улучшает сходимость (см. графики), несмотря на большую ошибку в начале. За 3 эпохи MSE уменьшается до **0.027** для BatchNorm и LayerNorm. С LayerNorm обучение проходит немного лучше.
2) Параллельные сверточные слои не влияют существенно на процесс обучения модели. MSE **0.08**.
3) Больше слоев также добавляет еще большую сложность, слишком усложняя модель для текущей задачи. Минимальный MSE **0.11**. Большая сложность ведет к переобучению - уже на 3 эпохе ошибка начинает расти.
4) Ранняя остановка показывает необходимое кол-во эпох. **5** эпох необходимо для baseline модели, чтобы достигнуть инимальный MSE **0.10**.</code></pre>
</div>
<div class="cell code" data-execution_count="30" data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb49"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SalaryPredictorNorm(SalaryPredictor):</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, is_layer_norm<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.is_layer_norm <span class="op">=</span> is_layer_norm</span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.title_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>            nn.Conv1d(<span class="va">self</span>.hid_size, <span class="va">self</span>.hid_size, kernel_size<span class="op">=</span>(<span class="dv">2</span>, )),</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.layer_norm(<span class="va">self</span>.hid_size, <span class="dv">8</span><span class="op">-</span><span class="dv">1</span>),</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveMaxPool1d(output_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.description_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>            nn.Conv1d(<span class="va">self</span>.hid_size, <span class="va">self</span>.hid_size, kernel_size<span class="op">=</span>(<span class="dv">2</span>, )),</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.layer_norm(<span class="va">self</span>.hid_size, <span class="dv">64</span><span class="op">-</span><span class="dv">1</span>),</span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb49-17"><a href="#cb49-17" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb49-18"><a href="#cb49-18" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveMaxPool1d(output_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb49-19"><a href="#cb49-19" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb49-20"><a href="#cb49-20" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.categorical_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb49-21"><a href="#cb49-21" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.n_cat_features, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb49-22"><a href="#cb49-22" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.layer_norm(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>, <span class="dv">0</span>),</span>
<span id="cb49-23"><a href="#cb49-23" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb49-24"><a href="#cb49-24" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb49-25"><a href="#cb49-25" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.layer_norm(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>, <span class="dv">0</span>),</span>
<span id="cb49-26"><a href="#cb49-26" aria-hidden="true" tabindex="-1"></a>            nn.ReLU()</span>
<span id="cb49-27"><a href="#cb49-27" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb49-28"><a href="#cb49-28" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.final_predictor <span class="op">=</span> nn.Sequential(</span>
<span id="cb49-29"><a href="#cb49-29" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>, <span class="va">self</span>.hid_size),</span>
<span id="cb49-30"><a href="#cb49-30" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.layer_norm(<span class="va">self</span>.hid_size, <span class="dv">0</span>),</span>
<span id="cb49-31"><a href="#cb49-31" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb49-32"><a href="#cb49-32" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size, <span class="dv">1</span>)</span>
<span id="cb49-33"><a href="#cb49-33" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb49-34"><a href="#cb49-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-35"><a href="#cb49-35" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> layer_norm(<span class="va">self</span>, a, b):</span>
<span id="cb49-36"><a href="#cb49-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.is_layer_norm:</span>
<span id="cb49-37"><a href="#cb49-37" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> b:</span>
<span id="cb49-38"><a href="#cb49-38" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> nn.LayerNorm([a, b])</span>
<span id="cb49-39"><a href="#cb49-39" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> nn.LayerNorm(a)</span>
<span id="cb49-40"><a href="#cb49-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.BatchNorm1d(a)</span>
<span id="cb49-41"><a href="#cb49-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-42"><a href="#cb49-42" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SalaryPredictorNorm()</span>
<span id="cb49-43"><a href="#cb49-43" aria-hidden="true" tabindex="-1"></a>train(model, BATCH_SIZE, EPOCHS, DEVICE, VECTOR_SIZES, <span class="st">&#39;SalaryPredictorBatchNorm&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb51"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;a690d58c5a0a4403827e1f353a76f06e&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 2.7002
Mean square error 0.0425
Mean absolute error 0.0809
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb53"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;6a1155858db44ce3b34d8910c69314c6&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.1186
Mean square error 0.0349
Mean absolute error 0.0726
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb55"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;4343d84a53134435b9400b577762d6b5&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.3912
Mean square error 0.0272
Mean absolute error 0.0629
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="34" data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb57"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>model_norm <span class="op">=</span> SalaryPredictorNorm(is_layer_norm<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a>train(model_norm, BATCH_SIZE, EPOCHS, DEVICE, VECTOR_SIZES, <span class="st">&#39;SalaryPredictorLayerNorm&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb59"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;1fd70d65f69d484d9a34c87a520b9540&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.1890
Mean square error 0.0607
Mean absolute error 0.0989
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb61"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;d7ff043d49cf40a29fa5d8334c84c695&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.0565
Mean square error 0.0360
Mean absolute error 0.0732
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb63"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;71ce0efd38ba42678d2f6253dbf2b72c&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.2655
Mean square error 0.0274
Mean absolute error 0.0625
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="33" data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SalaryPredictorParallelConv(SalaryPredictor):</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, <span class="op">**</span>kwargs):</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.final_predictor <span class="op">=</span> nn.Sequential(</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">6</span>, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>, <span class="va">self</span>.hid_size),</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size, <span class="dv">1</span>)</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, batch):</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>        title_embeddings <span class="op">=</span> <span class="va">self</span>.embedder(batch[<span class="st">&#39;Title&#39;</span>]).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>        title_features_1 <span class="op">=</span> <span class="va">self</span>.title_encoder(title_embeddings).squeeze()</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a>        title_features_2 <span class="op">=</span> <span class="va">self</span>.title_encoder(title_embeddings).squeeze()</span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>        title_features <span class="op">=</span> torch.cat([title_features_1, title_features_2], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a>        description_embeddings <span class="op">=</span> <span class="va">self</span>.embedder(batch[<span class="st">&#39;FullDescription&#39;</span>]).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a>        description_features_1 <span class="op">=</span> <span class="va">self</span>.description_encoder(description_embeddings).squeeze()</span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a>        description_features_2 <span class="op">=</span> <span class="va">self</span>.description_encoder(description_embeddings).squeeze()</span>
<span id="cb65-22"><a href="#cb65-22" aria-hidden="true" tabindex="-1"></a>        description_features <span class="op">=</span> torch.cat([description_features_1, description_features_2], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb65-23"><a href="#cb65-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-24"><a href="#cb65-24" aria-hidden="true" tabindex="-1"></a>        categorical_features <span class="op">=</span> <span class="va">self</span>.categorical_encoder(batch[<span class="st">&#39;Categorical&#39;</span>])</span>
<span id="cb65-25"><a href="#cb65-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-26"><a href="#cb65-26" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> torch.cat(</span>
<span id="cb65-27"><a href="#cb65-27" aria-hidden="true" tabindex="-1"></a>            [title_features, description_features, categorical_features], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb65-28"><a href="#cb65-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-29"><a href="#cb65-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.final_predictor(features).squeeze()</span>
<span id="cb65-30"><a href="#cb65-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-31"><a href="#cb65-31" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SalaryPredictorParallelConv()</span>
<span id="cb65-32"><a href="#cb65-32" aria-hidden="true" tabindex="-1"></a>train(model, BATCH_SIZE, EPOCHS, DEVICE, VECTOR_SIZES, <span class="st">&#39;SalaryPredictorParallelConv&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb67"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;9b863189689d4918b06dd1319256509b&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.0664
Mean square error 0.1305
Mean absolute error 0.1580
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb69"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;c4e5d021fa3f48e99cb285ee5f60a402&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.0575
Mean square error 0.0650
Mean absolute error 0.1051
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb71"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;9c864ffa691042f2af2fcd48f6f2c263&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.1804
Mean square error 0.0838
Mean absolute error 0.1251
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="35" data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb73"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SalaryPredictorStackMoreLayers(SalaryPredictor):</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.title_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a>            nn.Conv1d(<span class="va">self</span>.hid_size, <span class="va">self</span>.hid_size, kernel_size<span class="op">=</span>(<span class="dv">2</span>, )),</span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveMaxPool1d(output_size<span class="op">=</span><span class="dv">5</span>),</span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a>            nn.Conv1d(<span class="va">self</span>.hid_size, <span class="va">self</span>.hid_size, kernel_size<span class="op">=</span>(<span class="dv">2</span>, )),</span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb73-11"><a href="#cb73-11" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb73-12"><a href="#cb73-12" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveMaxPool1d(output_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb73-13"><a href="#cb73-13" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb73-14"><a href="#cb73-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.description_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb73-15"><a href="#cb73-15" aria-hidden="true" tabindex="-1"></a>            nn.Conv1d(<span class="va">self</span>.hid_size, <span class="va">self</span>.hid_size, kernel_size<span class="op">=</span>(<span class="dv">2</span>, )),</span>
<span id="cb73-16"><a href="#cb73-16" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb73-17"><a href="#cb73-17" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb73-18"><a href="#cb73-18" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveMaxPool1d(output_size<span class="op">=</span><span class="dv">5</span>),</span>
<span id="cb73-19"><a href="#cb73-19" aria-hidden="true" tabindex="-1"></a>            nn.Conv1d(<span class="va">self</span>.hid_size, <span class="va">self</span>.hid_size, kernel_size<span class="op">=</span>(<span class="dv">2</span>, )),</span>
<span id="cb73-20"><a href="#cb73-20" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb73-21"><a href="#cb73-21" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb73-22"><a href="#cb73-22" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveMaxPool1d(output_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb73-23"><a href="#cb73-23" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb73-24"><a href="#cb73-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.categorical_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb73-25"><a href="#cb73-25" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.n_cat_features, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb73-26"><a href="#cb73-26" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb73-27"><a href="#cb73-27" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb73-28"><a href="#cb73-28" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb73-29"><a href="#cb73-29" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb73-30"><a href="#cb73-30" aria-hidden="true" tabindex="-1"></a>            nn.ReLU()</span>
<span id="cb73-31"><a href="#cb73-31" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb73-32"><a href="#cb73-32" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.final_predictor <span class="op">=</span> nn.Sequential(</span>
<span id="cb73-33"><a href="#cb73-33" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb73-34"><a href="#cb73-34" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb73-35"><a href="#cb73-35" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>, <span class="va">self</span>.hid_size),</span>
<span id="cb73-36"><a href="#cb73-36" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb73-37"><a href="#cb73-37" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size, <span class="dv">1</span>)</span>
<span id="cb73-38"><a href="#cb73-38" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb73-39"><a href="#cb73-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb73-40"><a href="#cb73-40" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SalaryPredictorStackMoreLayers()</span>
<span id="cb73-41"><a href="#cb73-41" aria-hidden="true" tabindex="-1"></a>train(model, BATCH_SIZE, EPOCHS, DEVICE, VECTOR_SIZES, <span class="st">&#39;SalaryPredictorStackMoreLayers&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb75"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8b1b5e22253d4d8bb8594751c721d09f&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.0759
Mean square error 0.1151
Mean absolute error 0.1462
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb77"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8ff912cdcd8b4997a1856df557f28a9b&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.1443
Mean square error 0.0829
Mean absolute error 0.1213
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb79"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;30402dace330491592556b25c22f7f58&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.0767
Mean square error 0.0723
Mean absolute error 0.1133
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="36" data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb81"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_early_stopping(model, batch_size, epochs, device, vector_sizes, logdir<span class="op">=</span><span class="st">&#39;.&#39;</span>, patience<span class="op">=</span><span class="dv">1</span>, epsilon<span class="op">=</span><span class="fl">0.02</span>):</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>    writer <span class="op">=</span> SummaryWriter(log_dir<span class="op">=</span><span class="ss">f&#39;runs/</span><span class="sc">{</span>logdir<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> model.to(device)</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>    criterion <span class="op">=</span> nn.MSELoss(reduction<span class="op">=</span><span class="st">&#39;mean&#39;</span>)</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.Adam(model.parameters(), lr<span class="op">=</span><span class="fl">1e-3</span>)</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>    one_epoch_n_iterates <span class="op">=</span> <span class="bu">len</span>(data_train) <span class="op">/</span> batch_size</span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>    mae_list <span class="op">=</span> []</span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb81-11"><a href="#cb81-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(</span>
<span id="cb81-12"><a href="#cb81-12" aria-hidden="true" tabindex="-1"></a>                iterate_minibatches(data_train, batch_size<span class="op">=</span>batch_size, device<span class="op">=</span>device, max_lens<span class="op">=</span>vector_sizes)):</span>
<span id="cb81-13"><a href="#cb81-13" aria-hidden="true" tabindex="-1"></a>            model.train()</span>
<span id="cb81-14"><a href="#cb81-14" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> model(batch)</span>
<span id="cb81-15"><a href="#cb81-15" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb81-16"><a href="#cb81-16" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> criterion(pred, batch[TARGET_COLUMN])</span>
<span id="cb81-17"><a href="#cb81-17" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb81-18"><a href="#cb81-18" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb81-19"><a href="#cb81-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-20"><a href="#cb81-20" aria-hidden="true" tabindex="-1"></a>            writer.add_scalar(<span class="ss">f&#39;train/loss&#39;</span>, loss.item(), i <span class="op">+</span> epoch <span class="op">*</span> one_epoch_n_iterates)</span>
<span id="cb81-21"><a href="#cb81-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-22"><a href="#cb81-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">99</span>:</span>
<span id="cb81-23"><a href="#cb81-23" aria-hidden="true" tabindex="-1"></a>                mse, mae <span class="op">=</span> metrics(model, data_val, batch_size<span class="op">=</span>batch_size, device<span class="op">=</span>device, max_lens<span class="op">=</span>vector_sizes)</span>
<span id="cb81-24"><a href="#cb81-24" aria-hidden="true" tabindex="-1"></a>                writer.add_scalar(<span class="ss">f&#39;val/Mean square error&#39;</span>, mse, i <span class="op">+</span> epoch <span class="op">*</span> one_epoch_n_iterates)</span>
<span id="cb81-25"><a href="#cb81-25" aria-hidden="true" tabindex="-1"></a>                writer.add_scalar(<span class="ss">f&#39;val/Mean absolute error&#39;</span>, mae, i <span class="op">+</span> epoch <span class="op">*</span> one_epoch_n_iterates)</span>
<span id="cb81-26"><a href="#cb81-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;Train Loss </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb81-27"><a href="#cb81-27" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;Mean square error </span><span class="sc">{</span>mse<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb81-28"><a href="#cb81-28" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;Mean absolute error </span><span class="sc">{</span>mae<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb81-29"><a href="#cb81-29" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(mae_list) <span class="op">&lt;</span> patience:</span>
<span id="cb81-30"><a href="#cb81-30" aria-hidden="true" tabindex="-1"></a>            mae_list.append(mae)</span>
<span id="cb81-31"><a href="#cb81-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb81-32"><a href="#cb81-32" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> val <span class="kw">in</span> mae_list:</span>
<span id="cb81-33"><a href="#cb81-33" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> val <span class="op">-</span> mae <span class="op">&gt;</span> epsilon:</span>
<span id="cb81-34"><a href="#cb81-34" aria-hidden="true" tabindex="-1"></a>                    mae_list <span class="op">=</span> mae_list[<span class="dv">1</span>:] <span class="op">+</span> [mae]</span>
<span id="cb81-35"><a href="#cb81-35" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">break</span></span>
<span id="cb81-36"><a href="#cb81-36" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb81-37"><a href="#cb81-37" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="ss">f&#39;Early stopping after epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb81-38"><a href="#cb81-38" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb81-39"><a href="#cb81-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-40"><a href="#cb81-40" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SalaryPredictor()</span>
<span id="cb81-41"><a href="#cb81-41" aria-hidden="true" tabindex="-1"></a>train_early_stopping(model, batch_size<span class="op">=</span>BATCH_SIZE, epochs<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb81-42"><a href="#cb81-42" aria-hidden="true" tabindex="-1"></a>                     device<span class="op">=</span>DEVICE, vector_sizes<span class="op">=</span>VECTOR_SIZES,</span>
<span id="cb81-43"><a href="#cb81-43" aria-hidden="true" tabindex="-1"></a>                     logdir<span class="op">=</span><span class="st">&#39;SalaryPredictorEarlyStopping&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb83"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;e3b8fcdbe2e8480091734329dc24a68d&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.0756
Mean square error 0.4523
Mean absolute error 0.3210
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb85"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5f6e0ffd9607461eac729f94cf46a58b&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.1481
Mean square error 0.2803
Mean absolute error 0.2501
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb87"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;45691aa83abb4a648b37342e7c72df7e&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.1566
Mean square error 0.1592
Mean absolute error 0.1829
Epoch 3
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb89"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;f58e99464107409483fea3f906ac394e&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.0393
Mean square error 0.1228
Mean absolute error 0.1582
Epoch 4
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb91"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;364c706c2f2b459cb270e8a8403b14fc&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.1612
Mean square error 0.0966
Mean absolute error 0.1377
Epoch 5
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb93"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;d8c9dbb9d256491497f71f50827dc5c9&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.0146
Mean square error 0.1033
Mean absolute error 0.1442
Early stopping after epoch 5
</code></pre>
</div>
</div>
<div class="cell markdown">
<p><strong>2. Pooling слои стандартные (1 балла)</strong></p>
<ul>
<li>Опишите своими словами как работает Pooling слой.</li>
<li>Взять максимум по временной компоненте (незавимисо для каждой фичи)</li>
<li>Взять среднее по временной компоненте (исключая PAD символы)</li>
</ul>
<p>Применять можно к любой архитектуре (CNN/RNN)</p>
<p><strong>Pooling</strong> слой уменьшает размер слоя и помогает извлечь только значимые признаки, выбирая максимальное (MaxPool) значение или усредняя все значения (AvgPool) в рамках заданного окна.</p>
<p><strong>Выводы и <a href="https://tensorboard.dev/experiment/sOyIrKlBRTGmYkrSvh9p4g/#scalars&amp;runSelectionState=eyJTYWxhcnlQcmVkaWN0b3IiOnRydWUsIlNhbGFyeVByZWRpY3RvckF0dGVudGl2ZVBvb2xpbmciOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JBdmdQb29sIjp0cnVlLCJTYWxhcnlQcmVkaWN0b3JCYXRjaE5vcm0iOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JCaWRpcmVjdGlvbmFsTFNUTSI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvckVhcmx5U3RvcHBpbmciOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JMU1RNIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yTGF5ZXJOb3JtIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yTWF4UG9vbCI6dHJ1ZSwiU2FsYXJ5UHJlZGljdG9yUGFyYWxsZWxDb252IjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yUHJldHJhaW5lZEVtYmVkZGluZ3MiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JQcmV0cmFpbmVkRW1iZWRkaW5nc1RyYWluZWRXZWlnaHRzIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yUmFuZG9tRm9yZXN0IjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yU29mdG1heFBvb2xpbmciOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JTdGFja01vcmVMYXllcnMiOmZhbHNlfQ%3D%3D">Графики</a>:</strong> Pooling особо не влияет на качество модели (CNN с BatchNorm). Для MaxPool и AvgPool MSE <strong>0.03</strong>.</p>
</div>
<div class="cell code" data-execution_count="50" data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb95"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SalaryPredictorPooling(SalaryPredictor):</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, is_max_pool<span class="op">=</span><span class="va">False</span>, dim<span class="op">=</span><span class="dv">8</span>):</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.is_max_pool <span class="op">=</span> is_max_pool</span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dim <span class="op">=</span> dim</span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.title_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a>            nn.Conv1d(<span class="va">self</span>.dim, <span class="va">self</span>.hid_size, kernel_size<span class="op">=</span>(<span class="dv">2</span>, )),</span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size),</span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.pooling_layer(output_size<span class="op">=</span><span class="dv">4</span>),</span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveMaxPool1d(output_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb95-14"><a href="#cb95-14" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb95-15"><a href="#cb95-15" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.description_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb95-16"><a href="#cb95-16" aria-hidden="true" tabindex="-1"></a>            nn.Conv1d(<span class="va">self</span>.dim, <span class="va">self</span>.hid_size, kernel_size<span class="op">=</span>(<span class="dv">2</span>, )),</span>
<span id="cb95-17"><a href="#cb95-17" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size),</span>
<span id="cb95-18"><a href="#cb95-18" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.pooling_layer(output_size<span class="op">=</span><span class="dv">4</span>),</span>
<span id="cb95-19"><a href="#cb95-19" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb95-20"><a href="#cb95-20" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb95-21"><a href="#cb95-21" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveMaxPool1d(output_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb95-22"><a href="#cb95-22" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb95-23"><a href="#cb95-23" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.categorical_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb95-24"><a href="#cb95-24" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.n_cat_features, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">16</span>),</span>
<span id="cb95-25"><a href="#cb95-25" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">16</span>),</span>
<span id="cb95-26"><a href="#cb95-26" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.pooling_layer(output_size<span class="op">=</span><span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">8</span>),</span>
<span id="cb95-27"><a href="#cb95-27" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb95-28"><a href="#cb95-28" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">8</span>, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb95-29"><a href="#cb95-29" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb95-30"><a href="#cb95-30" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.pooling_layer(output_size<span class="op">=</span><span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb95-31"><a href="#cb95-31" aria-hidden="true" tabindex="-1"></a>            nn.ReLU()</span>
<span id="cb95-32"><a href="#cb95-32" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb95-33"><a href="#cb95-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.final_predictor <span class="op">=</span> nn.Sequential(</span>
<span id="cb95-34"><a href="#cb95-34" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>, <span class="va">self</span>.hid_size),</span>
<span id="cb95-35"><a href="#cb95-35" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size),</span>
<span id="cb95-36"><a href="#cb95-36" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb95-37"><a href="#cb95-37" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size, <span class="dv">1</span>)</span>
<span id="cb95-38"><a href="#cb95-38" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb95-39"><a href="#cb95-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-40"><a href="#cb95-40" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> pooling_layer(<span class="va">self</span>, output_size):</span>
<span id="cb95-41"><a href="#cb95-41" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.is_max_pool:</span>
<span id="cb95-42"><a href="#cb95-42" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> nn.AdaptiveMaxPool1d(output_size<span class="op">=</span>output_size)</span>
<span id="cb95-43"><a href="#cb95-43" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> nn.AdaptiveAvgPool1d(output_size<span class="op">=</span>output_size)</span>
<span id="cb95-44"><a href="#cb95-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-45"><a href="#cb95-45" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SalaryPredictorPooling(is_max_pool<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb95-46"><a href="#cb95-46" aria-hidden="true" tabindex="-1"></a>train(model, BATCH_SIZE, EPOCHS, DEVICE, VECTOR_SIZES, <span class="st">&#39;SalaryPredictorMaxPool&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb97"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;1e23bf23186047468903dffe8f5c8ed0&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 1.3435
Mean square error 0.0401
Mean absolute error 0.0771
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb99"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;1a4ad33aa89647a2870b8e46104033ae&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.9649
Mean square error 0.0341
Mean absolute error 0.0710
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb101"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;ce274f20a27546ed99b7f293aba8c4ed&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 2.2461
Mean square error 0.0297
Mean absolute error 0.0660
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="29" data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb103"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SalaryPredictorPooling()</span>
<span id="cb103-2"><a href="#cb103-2" aria-hidden="true" tabindex="-1"></a>train(model, BATCH_SIZE, EPOCHS, DEVICE, VECTOR_SIZES, <span class="st">&#39;SalaryPredictorAvgPool&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb105"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;6640e490acb14f30a6e3a21a65c801b6&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 3.6169
Mean square error 0.0482
Mean absolute error 0.0831
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb107"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;81a9d750a23e4acfbe1ea07dc2f2fa88&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 3.3580
Mean square error 0.0331
Mean absolute error 0.0698
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb109"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;bbb3ef4793ca40d390476a13931e4765&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 11.9864
Mean square error 0.0307
Mean absolute error 0.0668
</code></pre>
</div>
</div>
<div class="cell markdown" data-pycharm="{&quot;name&quot;:&quot;#%% md\n&quot;}">
<p><strong>3. Используйте предобученные эмбеддинги (2 балла)</strong></p>
<ul>
<li>Загрузите предобученные эмбеддинги с помощью gensim.downloader.load</li>
<li>Используйте метод <a href="https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html">from_pretrained</a> слоя torch.nn.Embedding для инициализации эмбеддингов с помощью предобученных весов. Можете попровать несколько типов предобученных эмбеддингов.</li>
<li>Проведите эксперементы с обучаемыми/замороженными весами эмбеддингов. Используйте одни и те же эмбеддинги для Title и FullDescription.</li>
</ul>
<p>Сравните результаты:</p>
<ol>
<li>Эмбеддингов, инициализируемых случайно из <span class="math display">𝒩(0,1)</span> (по умолчанию у слоя torch.nn.Embedding)</li>
<li>Предобученных эмбеддингов с замороженными весами</li>
<li>Предобученных эмбеддингов с обучаемыми весами</li>
</ol>
<p>Что изменяется в поведении модели? Какой эксперимент дал лучший результат?</p>
<p><strong>Выводы и <a href="https://tensorboard.dev/experiment/sOyIrKlBRTGmYkrSvh9p4g/#scalars&amp;runSelectionState=eyJTYWxhcnlQcmVkaWN0b3IiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JBdHRlbnRpdmVQb29saW5nIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yQXZnUG9vbCI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvckJhdGNoTm9ybSI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvckJpZGlyZWN0aW9uYWxMU1RNIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yRWFybHlTdG9wcGluZyI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvckxTVE0iOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JMYXllck5vcm0iOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JNYXhQb29sIjp0cnVlLCJTYWxhcnlQcmVkaWN0b3JQYXJhbGxlbENvbnYiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JQcmV0cmFpbmVkRW1iZWRkaW5ncyI6dHJ1ZSwiU2FsYXJ5UHJlZGljdG9yUHJldHJhaW5lZEVtYmVkZGluZ3NUcmFpbmVkV2VpZ2h0cyI6dHJ1ZSwiU2FsYXJ5UHJlZGljdG9yUmFuZG9tRm9yZXN0IjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yU29mdG1heFBvb2xpbmciOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JTdGFja01vcmVMYXllcnMiOmZhbHNlfQ%3D%3D">Графики</a>:</strong></p>
<pre><code>1) В эмбеддингах, инициализируемых случайно (SalaryPredictorMaxPool) MSE 0.03, а в предобученных **0.037** и **0.027** с замороженными и обучаемыми весами соответственно.
2) Если помимо обучения модели, еще и дообучать большие эмбеддинги, то время обучения увеличивается в разы, что неудобно и требует GPU, при этом качество увеличивается незначительно.</code></pre>
</div>
<div class="cell code" data-execution_count="48" data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb112"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gensim.downloader <span class="im">as</span> api</span>
<span id="cb112-2"><a href="#cb112-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-3"><a href="#cb112-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SalaryPredictorPretrainedEmbeddings(SalaryPredictorPooling):</span>
<span id="cb112-4"><a href="#cb112-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, pretrained_embedding, freeze<span class="op">=</span><span class="va">True</span>, <span class="op">**</span>kwargs):</span>
<span id="cb112-5"><a href="#cb112-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>(<span class="op">**</span>kwargs)</span>
<span id="cb112-6"><a href="#cb112-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.embedder <span class="op">=</span> nn.Embedding.from_pretrained(torch.Tensor(pretrained_embedding), freeze<span class="op">=</span>freeze)</span>
<span id="cb112-7"><a href="#cb112-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb112-8"><a href="#cb112-8" aria-hidden="true" tabindex="-1"></a>embed <span class="op">=</span> api.load(<span class="st">&#39;glove-wiki-gigaword-50&#39;</span>)</span>
<span id="cb112-9"><a href="#cb112-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SalaryPredictorPretrainedEmbeddings(embed.vectors, dim<span class="op">=</span><span class="dv">50</span>, is_max_pool<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb112-10"><a href="#cb112-10" aria-hidden="true" tabindex="-1"></a>train(model, BATCH_SIZE, EPOCHS, DEVICE, VECTOR_SIZES, <span class="st">&#39;SalaryPredictorPretrainedEmbeddings&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb114"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;6756d4108338443483a52e69678cd956&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 5.1737
Mean square error 0.0509
Mean absolute error 0.0859
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb116"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5662dcb87160445dbfb928177b0d46f8&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 1.8640
Mean square error 0.0435
Mean absolute error 0.0794
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb118"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;adf00fee8f5e43b1ba83146eaccb0784&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 3.3003
Mean square error 0.0373
Mean absolute error 0.0744
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="49" data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb120"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SalaryPredictorPretrainedEmbeddings(embed.vectors, freeze<span class="op">=</span><span class="va">False</span>, dim<span class="op">=</span><span class="dv">50</span>, is_max_pool<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>train(model, BATCH_SIZE, EPOCHS, DEVICE, VECTOR_SIZES, <span class="st">&#39;SalaryPredictorPretrainedEmbeddingsTrainedWeights&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb122"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb122-1"><a href="#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8123f30a5bd64467b039ff99390e2a13&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 9.0926
Mean square error 0.0368
Mean absolute error 0.0741
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb124"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;9bb92663159f40199823eb8fa1a92049&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 2.0870
Mean square error 0.0277
Mean absolute error 0.0634
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb126"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;2d589dc6ff8e4a50b6d8f31d4fe8ec2a&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 1.0606
Mean square error 0.0270
Mean absolute error 0.0633
</code></pre>
</div>
</div>
<div class="cell markdown">
<p><strong>4. Замените сверточные слои на рекуррентные (3 балла)</strong></p>
<ul>
<li>Замените сверточне слоим рекуррентными LSTM/GRU.</li>
<li>Проведите эксперимент с однонаправленной и двунаправленной рекуррентной нейросетью</li>
<li>Попробуйте найти удачный микс рекуррентных и сверточных слоев. Попробуйте разные миксы для Title и FullDescription</li>
</ul>
<p><strong>Выводы и <a href="https://tensorboard.dev/experiment/sOyIrKlBRTGmYkrSvh9p4g/#scalars&amp;runSelectionState=eyJTYWxhcnlQcmVkaWN0b3IiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JBdHRlbnRpdmVQb29saW5nIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yQXZnUG9vbCI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvckJhdGNoTm9ybSI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvckJpZGlyZWN0aW9uYWxMU1RNIjp0cnVlLCJTYWxhcnlQcmVkaWN0b3JFYXJseVN0b3BwaW5nIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yTFNUTSI6dHJ1ZSwiU2FsYXJ5UHJlZGljdG9yTGF5ZXJOb3JtIjp0cnVlLCJTYWxhcnlQcmVkaWN0b3JNYXhQb29sIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yUGFyYWxsZWxDb252IjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yUHJldHJhaW5lZEVtYmVkZGluZ3MiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JQcmV0cmFpbmVkRW1iZWRkaW5nc1RyYWluZWRXZWlnaHRzIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yUmFuZG9tRm9yZXN0IjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yU29mdG1heFBvb2xpbmciOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JTdGFja01vcmVMYXllcnMiOmZhbHNlfQ%3D%3D">Графики</a>:</strong></p>
<pre><code>1) В целом, рекурентные сети работают хуже, чем сверточные в данной задаче.
2) Однонаправленная сеть показывает качество немногим хуже, чем двунаправленная, MSE **0.046** и **0.027** соответственно.
3) Лучшее сочетание рекурентных и сверточных сетей - использовать только один слой LSTM, так как задача не требует большой и сложной модели.</code></pre>
</div>
<div class="cell code" data-execution_count="53" data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb129"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb129-1"><a href="#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SalaryPredictorLSTM(SalaryPredictor):</span>
<span id="cb129-2"><a href="#cb129-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, bidirectional<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb129-3"><a href="#cb129-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb129-4"><a href="#cb129-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-5"><a href="#cb129-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.LSTM <span class="op">=</span> nn.LSTM(<span class="va">self</span>.hid_size, <span class="va">self</span>.hid_size, bidirectional<span class="op">=</span>bidirectional)</span>
<span id="cb129-6"><a href="#cb129-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-7"><a href="#cb129-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.title_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb129-8"><a href="#cb129-8" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span> <span class="cf">if</span> bidirectional <span class="cf">else</span> <span class="va">self</span>.hid_size),</span>
<span id="cb129-9"><a href="#cb129-9" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb129-10"><a href="#cb129-10" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb129-11"><a href="#cb129-11" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveMaxPool1d(output_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb129-12"><a href="#cb129-12" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb129-13"><a href="#cb129-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-14"><a href="#cb129-14" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.description_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb129-15"><a href="#cb129-15" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span> <span class="cf">if</span> bidirectional <span class="cf">else</span> <span class="va">self</span>.hid_size),</span>
<span id="cb129-16"><a href="#cb129-16" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb129-17"><a href="#cb129-17" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb129-18"><a href="#cb129-18" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveMaxPool1d(output_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb129-19"><a href="#cb129-19" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb129-20"><a href="#cb129-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-21"><a href="#cb129-21" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.categorical_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb129-22"><a href="#cb129-22" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.n_cat_features, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb129-23"><a href="#cb129-23" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb129-24"><a href="#cb129-24" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb129-25"><a href="#cb129-25" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb129-26"><a href="#cb129-26" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb129-27"><a href="#cb129-27" aria-hidden="true" tabindex="-1"></a>            nn.ReLU()</span>
<span id="cb129-28"><a href="#cb129-28" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb129-29"><a href="#cb129-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.final_predictor <span class="op">=</span> nn.Sequential(</span>
<span id="cb129-30"><a href="#cb129-30" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> (<span class="dv">6</span> <span class="cf">if</span> bidirectional <span class="cf">else</span> <span class="dv">4</span>), <span class="va">self</span>.hid_size),</span>
<span id="cb129-31"><a href="#cb129-31" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size),</span>
<span id="cb129-32"><a href="#cb129-32" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb129-33"><a href="#cb129-33" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size, <span class="dv">1</span>)</span>
<span id="cb129-34"><a href="#cb129-34" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb129-35"><a href="#cb129-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-36"><a href="#cb129-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, batch):</span>
<span id="cb129-37"><a href="#cb129-37" aria-hidden="true" tabindex="-1"></a>        title_embeddings <span class="op">=</span> <span class="va">self</span>.embedder(batch[<span class="st">&#39;Title&#39;</span>])</span>
<span id="cb129-38"><a href="#cb129-38" aria-hidden="true" tabindex="-1"></a>        title_lstm, hidden <span class="op">=</span> <span class="va">self</span>.LSTM(title_embeddings)</span>
<span id="cb129-39"><a href="#cb129-39" aria-hidden="true" tabindex="-1"></a>        title_features <span class="op">=</span> <span class="va">self</span>.title_encoder(title_lstm.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)).squeeze()</span>
<span id="cb129-40"><a href="#cb129-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-41"><a href="#cb129-41" aria-hidden="true" tabindex="-1"></a>        description_embeddings <span class="op">=</span> <span class="va">self</span>.embedder(batch[<span class="st">&#39;FullDescription&#39;</span>])</span>
<span id="cb129-42"><a href="#cb129-42" aria-hidden="true" tabindex="-1"></a>        description_lstm, hidden <span class="op">=</span> <span class="va">self</span>.LSTM(description_embeddings)</span>
<span id="cb129-43"><a href="#cb129-43" aria-hidden="true" tabindex="-1"></a>        description_features <span class="op">=</span> <span class="va">self</span>.title_encoder(description_lstm.permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)).squeeze()</span>
<span id="cb129-44"><a href="#cb129-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-45"><a href="#cb129-45" aria-hidden="true" tabindex="-1"></a>        categorical_features <span class="op">=</span> <span class="va">self</span>.categorical_encoder(batch[<span class="st">&#39;Categorical&#39;</span>])</span>
<span id="cb129-46"><a href="#cb129-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-47"><a href="#cb129-47" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> torch.cat(</span>
<span id="cb129-48"><a href="#cb129-48" aria-hidden="true" tabindex="-1"></a>            [title_features, description_features, categorical_features], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb129-49"><a href="#cb129-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-50"><a href="#cb129-50" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.final_predictor(features).squeeze()</span>
<span id="cb129-51"><a href="#cb129-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb129-52"><a href="#cb129-52" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SalaryPredictorLSTM()</span>
<span id="cb129-53"><a href="#cb129-53" aria-hidden="true" tabindex="-1"></a>train(model, BATCH_SIZE, EPOCHS, DEVICE, VECTOR_SIZES, <span class="st">&#39;SalaryPredictorLSTM&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb131"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb131-1"><a href="#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;f0f733c608064a11924f0a65d5f2b07f&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 1.2841
Mean square error 0.2752
Mean absolute error 0.2342
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb133"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb133-1"><a href="#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;14e8feff148040b5a8e5833d73b2959a&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 2.7300
Mean square error 0.0937
Mean absolute error 0.1223
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb135"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;6407e47d197c4c408da0da9d9bf04b91&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.8173
Mean square error 0.0464
Mean absolute error 0.0834
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="56" data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb137"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SalaryPredictorLSTM(bidirectional<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb137-2"><a href="#cb137-2" aria-hidden="true" tabindex="-1"></a>train(model, BATCH_SIZE, EPOCHS, DEVICE, VECTOR_SIZES, <span class="st">&#39;SalaryPredictorBidirectionalLSTM&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb139"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;faf3d2b2cc93484faaefd2ae91543216&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.9477
Mean square error 0.0443
Mean absolute error 0.0828
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb141"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;1fcf3d5c763c4f1e86ffd656cd9fa4d0&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 5.4459
Mean square error 0.0319
Mean absolute error 0.0693
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb143"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;0c6a7f06c57a45849c1dfbf23aca80ae&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.7884
Mean square error 0.0272
Mean absolute error 0.0627
</code></pre>
</div>
</div>
<div class="cell markdown">
<p><strong>5. Вытащите признаки из нейронной сети и используйте их в ансамбле деревьев решений. (2 балла)</strong></p>
<ul>
<li>Вытащите признаки с предпоследнего слоя обученной нейросети и передайте их в ансамбль деревьев решений.</li>
<li>Сравните результаты работы лучшей нейросети и ансамбля деревьев решений, построенном на признаках из этой нейросети. Сможет ли замена последнего слоя на ансамбль деревьев решений улучшить результат?</li>
</ul>
<p><strong>Выводы и <a href="https://tensorboard.dev/experiment/sOyIrKlBRTGmYkrSvh9p4g/#scalars&amp;runSelectionState=eyJTYWxhcnlQcmVkaWN0b3IiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JBdHRlbnRpdmVQb29saW5nIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yQXZnUG9vbCI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvckJhdGNoTm9ybSI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvckJpZGlyZWN0aW9uYWxMU1RNIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yRWFybHlTdG9wcGluZyI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvckxTVE0iOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JMYXllck5vcm0iOnRydWUsIlNhbGFyeVByZWRpY3Rvck1heFBvb2wiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JQYXJhbGxlbENvbnYiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JQcmV0cmFpbmVkRW1iZWRkaW5ncyI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvclByZXRyYWluZWRFbWJlZGRpbmdzVHJhaW5lZFdlaWdodHMiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JSYW5kb21Gb3Jlc3QiOnRydWUsIlNhbGFyeVByZWRpY3RvclNvZnRtYXhQb29saW5nIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yU3RhY2tNb3JlTGF5ZXJzIjpmYWxzZX0%3D">Графики</a>:</strong></p>
<pre><code>1) Ансамбль деревьев решений в качестве регрессора работает также (MSE **0.028**), чем лучшая нейросеть (с нормированием по слоям SalaryPredictorLayerNorm MSE 0.027).
2) Лес деревьев очень быстро сходится к малым значениям ошибки.</code></pre>
</div>
<div class="cell code" data-execution_count="57" data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb146"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb146-1"><a href="#cb146-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestRegressor</span>
<span id="cb146-2"><a href="#cb146-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_absolute_error, mean_squared_error</span>
<span id="cb146-3"><a href="#cb146-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.models.feature_extraction <span class="im">import</span> create_feature_extractor</span>
<span id="cb146-4"><a href="#cb146-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-5"><a href="#cb146-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_tree_ensemble(model, regressor, batch_size, epochs, device, vector_sizes, logdir<span class="op">=</span><span class="st">&#39;.&#39;</span>):</span>
<span id="cb146-6"><a href="#cb146-6" aria-hidden="true" tabindex="-1"></a>    writer <span class="op">=</span> SummaryWriter(log_dir<span class="op">=</span><span class="ss">f&#39;runs/</span><span class="sc">{</span>logdir<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb146-7"><a href="#cb146-7" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> model.to(device)</span>
<span id="cb146-8"><a href="#cb146-8" aria-hidden="true" tabindex="-1"></a>    one_epoch_n_iterates <span class="op">=</span> <span class="bu">len</span>(data_train) <span class="op">/</span> batch_size</span>
<span id="cb146-9"><a href="#cb146-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-10"><a href="#cb146-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(epochs):</span>
<span id="cb146-11"><a href="#cb146-11" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Epoch </span><span class="sc">{</span>epoch<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb146-12"><a href="#cb146-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(</span>
<span id="cb146-13"><a href="#cb146-13" aria-hidden="true" tabindex="-1"></a>                iterate_minibatches(data_train, batch_size<span class="op">=</span>batch_size, device<span class="op">=</span>device, max_lens<span class="op">=</span>vector_sizes)):</span>
<span id="cb146-14"><a href="#cb146-14" aria-hidden="true" tabindex="-1"></a>            features <span class="op">=</span> model(batch)[<span class="st">&#39;layer&#39;</span>].detach().cpu().numpy()</span>
<span id="cb146-15"><a href="#cb146-15" aria-hidden="true" tabindex="-1"></a>            regressor.fit(features, batch[TARGET_COLUMN])</span>
<span id="cb146-16"><a href="#cb146-16" aria-hidden="true" tabindex="-1"></a>            pred <span class="op">=</span> regressor.predict(features)</span>
<span id="cb146-17"><a href="#cb146-17" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> mean_squared_error(batch[TARGET_COLUMN], pred)</span>
<span id="cb146-18"><a href="#cb146-18" aria-hidden="true" tabindex="-1"></a>            writer.add_scalar(<span class="ss">f&#39;train/loss&#39;</span>, loss, i <span class="op">+</span> epoch <span class="op">*</span> one_epoch_n_iterates)</span>
<span id="cb146-19"><a href="#cb146-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-20"><a href="#cb146-20" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">%</span> <span class="dv">100</span> <span class="op">==</span> <span class="dv">99</span>:</span>
<span id="cb146-21"><a href="#cb146-21" aria-hidden="true" tabindex="-1"></a>                mse, mae <span class="op">=</span> metrics_forest(model, regressor, data_val, batch_size<span class="op">=</span>batch_size, device<span class="op">=</span>device, max_lens<span class="op">=</span>vector_sizes)</span>
<span id="cb146-22"><a href="#cb146-22" aria-hidden="true" tabindex="-1"></a>                writer.add_scalar(<span class="ss">f&#39;val/Mean square error&#39;</span>, mse, i <span class="op">+</span> epoch <span class="op">*</span> one_epoch_n_iterates)</span>
<span id="cb146-23"><a href="#cb146-23" aria-hidden="true" tabindex="-1"></a>                writer.add_scalar(<span class="ss">f&#39;val/Mean absolute error&#39;</span>, mae, i <span class="op">+</span> epoch <span class="op">*</span> one_epoch_n_iterates)</span>
<span id="cb146-24"><a href="#cb146-24" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;Train Loss </span><span class="sc">{</span>loss<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb146-25"><a href="#cb146-25" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;Mean square error </span><span class="sc">{</span>mse<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb146-26"><a href="#cb146-26" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&#39;Mean absolute error </span><span class="sc">{</span>mae<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb146-27"><a href="#cb146-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> regressor</span>
<span id="cb146-28"><a href="#cb146-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-29"><a href="#cb146-29" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> metrics_forest(model, regressor, data, batch_size<span class="op">=</span>BATCH_SIZE, <span class="op">**</span>kw):</span>
<span id="cb146-30"><a href="#cb146-30" aria-hidden="true" tabindex="-1"></a>    squared_error <span class="op">=</span> abs_error <span class="op">=</span> num_samples <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb146-31"><a href="#cb146-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> batch <span class="kw">in</span> iterate_minibatches(data, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">False</span>, tqdm<span class="op">=</span><span class="va">False</span>, <span class="op">**</span>kw):</span>
<span id="cb146-32"><a href="#cb146-32" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> model(batch)[<span class="st">&#39;layer&#39;</span>].detach().cpu().numpy()</span>
<span id="cb146-33"><a href="#cb146-33" aria-hidden="true" tabindex="-1"></a>        batch_pred <span class="op">=</span> regressor.predict(features)</span>
<span id="cb146-34"><a href="#cb146-34" aria-hidden="true" tabindex="-1"></a>        squared_error <span class="op">+=</span> mean_squared_error(batch[TARGET_COLUMN], batch_pred)</span>
<span id="cb146-35"><a href="#cb146-35" aria-hidden="true" tabindex="-1"></a>        abs_error <span class="op">+=</span> mean_absolute_error(batch[TARGET_COLUMN], batch_pred)</span>
<span id="cb146-36"><a href="#cb146-36" aria-hidden="true" tabindex="-1"></a>        num_samples <span class="op">+=</span> <span class="bu">len</span>(batch)</span>
<span id="cb146-37"><a href="#cb146-37" aria-hidden="true" tabindex="-1"></a>    mse <span class="op">=</span> squared_error <span class="op">/</span> num_samples</span>
<span id="cb146-38"><a href="#cb146-38" aria-hidden="true" tabindex="-1"></a>    mae <span class="op">=</span> abs_error <span class="op">/</span> num_samples</span>
<span id="cb146-39"><a href="#cb146-39" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> mse, mae</span>
<span id="cb146-40"><a href="#cb146-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-41"><a href="#cb146-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb146-42"><a href="#cb146-42" aria-hidden="true" tabindex="-1"></a>model_no_last_layer <span class="op">=</span> create_feature_extractor(model_norm, return_nodes<span class="op">=</span>{<span class="st">&#39;final_predictor.2&#39;</span>: <span class="st">&#39;layer&#39;</span>})</span>
<span id="cb146-43"><a href="#cb146-43" aria-hidden="true" tabindex="-1"></a>regr <span class="op">=</span> RandomForestRegressor(n_estimators<span class="op">=</span><span class="dv">5</span>, max_depth<span class="op">=</span><span class="dv">2</span>, random_state<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb146-44"><a href="#cb146-44" aria-hidden="true" tabindex="-1"></a>regr <span class="op">=</span> train_tree_ensemble(model_no_last_layer, regr, batch_size<span class="op">=</span>BATCH_SIZE, epochs<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb146-45"><a href="#cb146-45" aria-hidden="true" tabindex="-1"></a>                           device<span class="op">=</span>DEVICE, vector_sizes<span class="op">=</span>VECTOR_SIZES, logdir<span class="op">=</span><span class="st">&#39;SalaryPredictorRandomForest&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb148"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb148-1"><a href="#cb148-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;e79471db18eb4515b0516d8957b3bade&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.0307
Mean square error 0.0302
Mean absolute error 0.0667
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb150"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb150-1"><a href="#cb150-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8ce1bca6ac8f454abf1dcf4736cd482b&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.0935
Mean square error 0.0293
Mean absolute error 0.0658
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb152"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb152-1"><a href="#cb152-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;b12e766e71e244288d4fa72357492f8e&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.0034
Mean square error 0.0279
Mean absolute error 0.0640
</code></pre>
</div>
</div>
<div class="cell markdown">
<p><strong>6. Pooling слои <em>продвинутые</em> (3 балла)</strong></p>
<p>Реализуйте и примените Softmax-pooling:<span class="math display">$$ out_{i, t} = \sum_t {h_{i,t} \cdot {{e ^ {h_{i, t}}} \over \sum_\tau e ^ {h_{j, \tau}} } }$$</span></p>
<p>Attentive pooling<span class="math display"><em>o</em><em>u</em><em>t</em><sub><em>i</em>, <em>t</em></sub> = ∑<sub><em>t</em></sub><em>h</em><sub><em>i</em>, <em>t</em></sub> ⋅ <em>A</em><em>t</em><em>t</em><em>n</em>(<em>h</em><sub><em>t</em></sub>)</span></p>
<p>, где <span class="math display">$$ Attn(h_t) = {{e ^ {NN_{attn}(h_t)}} \over \sum_\tau e ^ {NN_{attn}(h_\tau)}}  $$</span>и <span class="math inline"><em>N</em><em>N</em><sub><em>a</em><em>t</em><em>t</em><em>n</em></sub></span> полносвязный слой.</p>
<p><strong>Выводы и <a href="https://tensorboard.dev/experiment/sOyIrKlBRTGmYkrSvh9p4g/#scalars&amp;runSelectionState=eyJTYWxhcnlQcmVkaWN0b3IiOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JBdHRlbnRpdmVQb29saW5nIjp0cnVlLCJTYWxhcnlQcmVkaWN0b3JBdmdQb29sIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yQmF0Y2hOb3JtIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yQmlkaXJlY3Rpb25hbExTVE0iOmZhbHNlLCJTYWxhcnlQcmVkaWN0b3JFYXJseVN0b3BwaW5nIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yTFNUTSI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvckxheWVyTm9ybSI6dHJ1ZSwiU2FsYXJ5UHJlZGljdG9yTWF4UG9vbCI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvclBhcmFsbGVsQ29udiI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvclByZXRyYWluZWRFbWJlZGRpbmdzIjpmYWxzZSwiU2FsYXJ5UHJlZGljdG9yUHJldHJhaW5lZEVtYmVkZGluZ3NUcmFpbmVkV2VpZ2h0cyI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvclJhbmRvbUZvcmVzdCI6ZmFsc2UsIlNhbGFyeVByZWRpY3RvclNvZnRtYXhQb29saW5nIjp0cnVlLCJTYWxhcnlQcmVkaWN0b3JTdGFja01vcmVMYXllcnMiOmZhbHNlfQ%3D%3D">Графики</a>:</strong> Продвинутые методы пулинга помогают значительно улучшать качество сети. MSE <strong>0.05</strong> и <strong>0.024</strong> для Softmax и Attentive Pooling соотвественно.</p>
</div>
<div class="cell code" data-execution_count="58" data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb154"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SalaryPredictorSoftmaxPooling(SalaryPredictor):</span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dim<span class="op">=</span><span class="dv">8</span>):</span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dim <span class="op">=</span> dim</span>
<span id="cb154-5"><a href="#cb154-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-6"><a href="#cb154-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.title_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb154-7"><a href="#cb154-7" aria-hidden="true" tabindex="-1"></a>            nn.Conv1d(<span class="va">self</span>.dim, <span class="va">self</span>.hid_size, kernel_size<span class="op">=</span>(<span class="dv">2</span>, )),</span>
<span id="cb154-8"><a href="#cb154-8" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size),</span>
<span id="cb154-9"><a href="#cb154-9" aria-hidden="true" tabindex="-1"></a>            nn.Softmax(dim<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb154-10"><a href="#cb154-10" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveAvgPool1d(output_size<span class="op">=</span><span class="dv">4</span>),</span>
<span id="cb154-11"><a href="#cb154-11" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb154-12"><a href="#cb154-12" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb154-13"><a href="#cb154-13" aria-hidden="true" tabindex="-1"></a>            nn.Softmax(dim<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb154-14"><a href="#cb154-14" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveMaxPool1d(output_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb154-15"><a href="#cb154-15" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb154-16"><a href="#cb154-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.description_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb154-17"><a href="#cb154-17" aria-hidden="true" tabindex="-1"></a>            nn.Conv1d(<span class="va">self</span>.dim, <span class="va">self</span>.hid_size, kernel_size<span class="op">=</span>(<span class="dv">2</span>, )),</span>
<span id="cb154-18"><a href="#cb154-18" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size),</span>
<span id="cb154-19"><a href="#cb154-19" aria-hidden="true" tabindex="-1"></a>            nn.Softmax(dim<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb154-20"><a href="#cb154-20" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveAvgPool1d(output_size<span class="op">=</span><span class="dv">4</span>),</span>
<span id="cb154-21"><a href="#cb154-21" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb154-22"><a href="#cb154-22" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb154-23"><a href="#cb154-23" aria-hidden="true" tabindex="-1"></a>            nn.Softmax(dim<span class="op">=</span><span class="dv">2</span>),</span>
<span id="cb154-24"><a href="#cb154-24" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveMaxPool1d(output_size<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb154-25"><a href="#cb154-25" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb154-26"><a href="#cb154-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.categorical_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb154-27"><a href="#cb154-27" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.n_cat_features, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">16</span>),</span>
<span id="cb154-28"><a href="#cb154-28" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">16</span>),</span>
<span id="cb154-29"><a href="#cb154-29" aria-hidden="true" tabindex="-1"></a>            nn.Softmax(dim<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb154-30"><a href="#cb154-30" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveAvgPool1d(output_size<span class="op">=</span><span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">8</span>),</span>
<span id="cb154-31"><a href="#cb154-31" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb154-32"><a href="#cb154-32" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">8</span>, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb154-33"><a href="#cb154-33" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb154-34"><a href="#cb154-34" aria-hidden="true" tabindex="-1"></a>            nn.Softmax(dim<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb154-35"><a href="#cb154-35" aria-hidden="true" tabindex="-1"></a>            nn.AdaptiveAvgPool1d(output_size<span class="op">=</span><span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">2</span>),</span>
<span id="cb154-36"><a href="#cb154-36" aria-hidden="true" tabindex="-1"></a>            nn.ReLU()</span>
<span id="cb154-37"><a href="#cb154-37" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb154-38"><a href="#cb154-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.final_predictor <span class="op">=</span> nn.Sequential(</span>
<span id="cb154-39"><a href="#cb154-39" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>, <span class="va">self</span>.hid_size),</span>
<span id="cb154-40"><a href="#cb154-40" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size),</span>
<span id="cb154-41"><a href="#cb154-41" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb154-42"><a href="#cb154-42" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size, <span class="dv">1</span>)</span>
<span id="cb154-43"><a href="#cb154-43" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb154-44"><a href="#cb154-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb154-45"><a href="#cb154-45" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SalaryPredictorSoftmaxPooling()</span>
<span id="cb154-46"><a href="#cb154-46" aria-hidden="true" tabindex="-1"></a>train(model, BATCH_SIZE, EPOCHS, DEVICE, VECTOR_SIZES, <span class="st">&#39;SalaryPredictorSoftmaxPooling&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb156"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb156-1"><a href="#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;cbce455559f841dfbfe6b627becf1ffd&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 4.4157
Mean square error 0.0420
Mean absolute error 0.0804
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb158"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;d472d99e82b84bdf884e1bd5495fc3f5&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.2501
Mean square error 0.0486
Mean absolute error 0.0858
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb160"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb160-1"><a href="#cb160-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8dd3a511dc6c4f84bcbab5a81091e994&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.9460
Mean square error 0.0658
Mean absolute error 0.1042
</code></pre>
</div>
</div>
<div class="cell code" data-execution_count="59" data-pycharm="{&quot;name&quot;:&quot;#%%\n&quot;}">
<div class="sourceCode" id="cb162"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Attention(nn.Module):</span>
<span id="cb162-2"><a href="#cb162-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, hidden_size):</span>
<span id="cb162-3"><a href="#cb162-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb162-4"><a href="#cb162-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.U <span class="op">=</span> nn.Parameter(torch.randn(hidden_size, hidden_size))</span>
<span id="cb162-5"><a href="#cb162-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-6"><a href="#cb162-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, A, B):</span>
<span id="cb162-7"><a href="#cb162-7" aria-hidden="true" tabindex="-1"></a>        G <span class="op">=</span> A.transpose(<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">2</span>) <span class="op">@</span> <span class="va">self</span>.U.expand(A.shape[<span class="dv">0</span>], <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>) <span class="op">@</span> B</span>
<span id="cb162-8"><a href="#cb162-8" aria-hidden="true" tabindex="-1"></a>        G <span class="op">=</span> torch.tanh(G)</span>
<span id="cb162-9"><a href="#cb162-9" aria-hidden="true" tabindex="-1"></a>        A_pooling <span class="op">=</span> G.<span class="bu">max</span>(dim<span class="op">=-</span><span class="dv">1</span>)[<span class="dv">0</span>]</span>
<span id="cb162-10"><a href="#cb162-10" aria-hidden="true" tabindex="-1"></a>        B_pooling <span class="op">=</span> G.<span class="bu">max</span>(dim<span class="op">=-</span><span class="dv">2</span>)[<span class="dv">0</span>]</span>
<span id="cb162-11"><a href="#cb162-11" aria-hidden="true" tabindex="-1"></a>        A_pooling <span class="op">=</span> A_pooling.softmax(dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb162-12"><a href="#cb162-12" aria-hidden="true" tabindex="-1"></a>        B_pooling <span class="op">=</span> B_pooling.softmax(dim<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb162-13"><a href="#cb162-13" aria-hidden="true" tabindex="-1"></a>        ra <span class="op">=</span> A <span class="op">@</span> A_pooling.unsqueeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb162-14"><a href="#cb162-14" aria-hidden="true" tabindex="-1"></a>        rb <span class="op">=</span> B <span class="op">@</span> B_pooling.unsqueeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb162-15"><a href="#cb162-15" aria-hidden="true" tabindex="-1"></a>        ra <span class="op">=</span> ra.squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb162-16"><a href="#cb162-16" aria-hidden="true" tabindex="-1"></a>        rb <span class="op">=</span> rb.squeeze(<span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb162-17"><a href="#cb162-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ra, rb</span>
<span id="cb162-18"><a href="#cb162-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-19"><a href="#cb162-19" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> SalaryPredictorAttentivePooling(SalaryPredictor):</span>
<span id="cb162-20"><a href="#cb162-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dim<span class="op">=</span><span class="dv">8</span>):</span>
<span id="cb162-21"><a href="#cb162-21" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb162-22"><a href="#cb162-22" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dim <span class="op">=</span> dim</span>
<span id="cb162-23"><a href="#cb162-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-24"><a href="#cb162-24" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.title_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb162-25"><a href="#cb162-25" aria-hidden="true" tabindex="-1"></a>            nn.Conv1d(<span class="va">self</span>.dim, <span class="va">self</span>.hid_size, kernel_size<span class="op">=</span>(<span class="dv">2</span>, )),</span>
<span id="cb162-26"><a href="#cb162-26" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size),</span>
<span id="cb162-27"><a href="#cb162-27" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb162-28"><a href="#cb162-28" aria-hidden="true" tabindex="-1"></a>            nn.ReLU()</span>
<span id="cb162-29"><a href="#cb162-29" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb162-30"><a href="#cb162-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.description_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb162-31"><a href="#cb162-31" aria-hidden="true" tabindex="-1"></a>            nn.Conv1d(<span class="va">self</span>.dim, <span class="va">self</span>.hid_size, kernel_size<span class="op">=</span>(<span class="dv">2</span>, )),</span>
<span id="cb162-32"><a href="#cb162-32" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size),</span>
<span id="cb162-33"><a href="#cb162-33" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(p<span class="op">=</span><span class="fl">0.25</span>),</span>
<span id="cb162-34"><a href="#cb162-34" aria-hidden="true" tabindex="-1"></a>            nn.ReLU()</span>
<span id="cb162-35"><a href="#cb162-35" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb162-36"><a href="#cb162-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.attentive_pooling <span class="op">=</span> Attention(<span class="va">self</span>.hid_size)</span>
<span id="cb162-37"><a href="#cb162-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.categorical_encoder <span class="op">=</span> nn.Sequential(</span>
<span id="cb162-38"><a href="#cb162-38" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.n_cat_features, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">8</span>),</span>
<span id="cb162-39"><a href="#cb162-39" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">8</span>),</span>
<span id="cb162-40"><a href="#cb162-40" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb162-41"><a href="#cb162-41" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">8</span>, <span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb162-42"><a href="#cb162-42" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">4</span>),</span>
<span id="cb162-43"><a href="#cb162-43" aria-hidden="true" tabindex="-1"></a>            nn.ReLU()</span>
<span id="cb162-44"><a href="#cb162-44" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb162-45"><a href="#cb162-45" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.final_predictor <span class="op">=</span> nn.Sequential(</span>
<span id="cb162-46"><a href="#cb162-46" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size <span class="op">*</span> <span class="dv">6</span>, <span class="va">self</span>.hid_size),</span>
<span id="cb162-47"><a href="#cb162-47" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="va">self</span>.hid_size),</span>
<span id="cb162-48"><a href="#cb162-48" aria-hidden="true" tabindex="-1"></a>            nn.ReLU(),</span>
<span id="cb162-49"><a href="#cb162-49" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.hid_size, <span class="dv">1</span>)</span>
<span id="cb162-50"><a href="#cb162-50" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb162-51"><a href="#cb162-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-52"><a href="#cb162-52" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, batch):</span>
<span id="cb162-53"><a href="#cb162-53" aria-hidden="true" tabindex="-1"></a>        title_embeddings <span class="op">=</span> <span class="va">self</span>.embedder(batch[<span class="st">&#39;Title&#39;</span>]).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb162-54"><a href="#cb162-54" aria-hidden="true" tabindex="-1"></a>        title_features <span class="op">=</span> <span class="va">self</span>.title_encoder(title_embeddings)</span>
<span id="cb162-55"><a href="#cb162-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-56"><a href="#cb162-56" aria-hidden="true" tabindex="-1"></a>        description_embeddings <span class="op">=</span> <span class="va">self</span>.embedder(batch[<span class="st">&#39;FullDescription&#39;</span>]).permute(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb162-57"><a href="#cb162-57" aria-hidden="true" tabindex="-1"></a>        description_features <span class="op">=</span> <span class="va">self</span>.description_encoder(description_embeddings)</span>
<span id="cb162-58"><a href="#cb162-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-59"><a href="#cb162-59" aria-hidden="true" tabindex="-1"></a>        categorical_features <span class="op">=</span> <span class="va">self</span>.categorical_encoder(batch[<span class="st">&#39;Categorical&#39;</span>])</span>
<span id="cb162-60"><a href="#cb162-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-61"><a href="#cb162-61" aria-hidden="true" tabindex="-1"></a>        colmax, rowmax <span class="op">=</span> <span class="va">self</span>.attentive_pooling(title_features, description_features)</span>
<span id="cb162-62"><a href="#cb162-62" aria-hidden="true" tabindex="-1"></a>        features <span class="op">=</span> torch.cat(</span>
<span id="cb162-63"><a href="#cb162-63" aria-hidden="true" tabindex="-1"></a>            [colmax.squeeze(), rowmax.squeeze(), categorical_features], dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb162-64"><a href="#cb162-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-65"><a href="#cb162-65" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.final_predictor(features).squeeze()</span>
<span id="cb162-66"><a href="#cb162-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb162-67"><a href="#cb162-67" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> SalaryPredictorAttentivePooling()</span>
<span id="cb162-68"><a href="#cb162-68" aria-hidden="true" tabindex="-1"></a>train(model, BATCH_SIZE, EPOCHS, DEVICE, VECTOR_SIZES, <span class="st">&#39;SalaryPredictorAttentivePooling&#39;</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Epoch 0
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb164"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;115f4d33bc464d03b67717709c90fe40&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 0.7478
Mean square error 0.0347
Mean absolute error 0.0719
Epoch 1
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb166"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb166-1"><a href="#cb166-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;c41d7196190944008de7933ca710a5ff&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 11.0152
Mean square error 0.0271
Mean absolute error 0.0627
Epoch 2
</code></pre>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb168"><pre class="sourceCode json"><code class="sourceCode json"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">,</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;952a7fa29ca24e6aa3e4229b850415ba&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stdout">
<pre><code>Train Loss 5.1260
Mean square error 0.0241
Mean absolute error 0.0589
</code></pre>
</div>
</div>
</body>
</html>
